{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RepresentRNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/juglar-diaz/STTD/blob/master/RepresentRNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "c02j_-p6TZ2r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Intro"
      ]
    },
    {
      "metadata": {
        "id": "R3QjBnH6lktK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LJWrJduhlnI-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jGPfqOgRnsBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "e3a4ed1d-112a-4a2c-ab4e-e7266d059b2e"
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "!pip3 install torch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 31kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5a1c2000 @  0x7ffa5b10d1c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4YaP_5IRU1Ar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e467c10c-af74-48d9-979b-ccc8e0517e31"
      },
      "cell_type": "code",
      "source": [
        "print(accelerator)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cu80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lboU3CzKkHsc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torch.functional as F\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import itertools\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "torch.manual_seed(1)\n",
        "\n",
        "\n",
        "import pickle\n",
        "\n",
        "import os\n",
        "sep = os.sep\n",
        "import os.path\n",
        "\n",
        "data = \"\"\n",
        "import pandas as pd\n",
        "import bisect\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "id7ExeAEnvbv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    inGPU = True\n",
        "    _type = torch.cuda.FloatTensor\n",
        "    _typelong = torch.cuda.LongTensor\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    inGPU = False\n",
        "    _type = torch.FloatTensor\n",
        "    _typelong = torch.LongTensor\n",
        "    device = torch.device(\"cpu\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s6m5UOXClc5v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Data"
      ]
    },
    {
      "metadata": {
        "id": "Nrks3-MplPnI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "exchangedrive = drive.CreateFile({'id':'1cMCzlvTMlUPgaYaUIdlMVtTpp8r10GnX'})\n",
        "exchangedrive.GetContentFile('robosclean.p')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fqinedc4lvh2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "exchangedrive = drive.CreateFile({'id':'1A5Wa6LiaGs8XeW2S2qjGbcoSSlsMGW97'})\n",
        "exchangedrive.GetContentFile('tweetsLAtrain.csv')\n",
        "exchangedrive = drive.CreateFile({'id':'1CrUCS7oWzdvYoFwtWgikiGkDAu6w3dOF'})\n",
        "exchangedrive.GetContentFile('tweetsLAtest.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYQvo_-Alvl_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "exchangedrive = drive.CreateFile({'id':'1NuSVM7-h0CCRtzi0woM4h5tVd6T7JO2C'})\n",
        "exchangedrive.GetContentFile('tweetsNYtrain.csv')\n",
        "exchangedrive = drive.CreateFile({'id':'1UYZY0sh1-Q8MIofMAHDGaNKv8cfDA0ui'})\n",
        "exchangedrive.GetContentFile('tweetsNYtest.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w5iLxHb8lvqa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "exchangedrive = drive.CreateFile({'id':'1Jv19eJTZwsZWEA_rUudvKwcn1TS-DFBa'})\n",
        "exchangedrive.GetContentFile('tweets2016_2half.csv')\n",
        "exchangedrive = drive.CreateFile({'id':'1E8WlhOXb3tfQbLUpizx7QXzeydv57eXN'})\n",
        "exchangedrive.GetContentFile('toy_2017_Jan.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "42Nlwku5krUZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def buildIndexData(list_elements, start_index = 0):\n",
        "\n",
        "    idx2data = {index + start_index: discretization for index, discretization in enumerate(set(list_elements))}\n",
        "\n",
        "    data2idx = {discretization: index for index, discretization in idx2data.items()}\n",
        "\n",
        "    indexes = [data2idx[element] for element in list_elements]\n",
        "\n",
        "    return indexes, data2idx, idx2data\n",
        "\n",
        "\n",
        "class Discretize:\n",
        "    def fit_transform(self):\n",
        "        pass\n",
        "\n",
        "    def transform(self):\n",
        "        pass\n",
        "\n",
        "    def updateIndexes(self, indexes, star_index):\n",
        "        map_indexes = {value:counter+star_index for counter, value in enumerate(set(indexes))}\n",
        "\n",
        "\n",
        "        new_indexes = [map_indexes[index] for index in indexes]\n",
        "\n",
        "        idx2data = {map_indexes[index]:self.idx_data[index] for index in set(indexes)}\n",
        "        data2idx = {val:key for (key, val) in idx2data.items()}\n",
        "\n",
        "        self.idx_data = idx2data\n",
        "        self.data_idx = data2idx\n",
        "\n",
        "        return new_indexes\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WpcjzVxBkKbS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Round(Discretize):\n",
        "    def __init__(self, div= 10):\n",
        "        self.div= div\n",
        "\n",
        "    def fit_transform(self, latitudes, longitudes, start_index = 0, vocab_size = -1, vocab_min_count=0):\n",
        "        lat = (latitudes * self.div).astype(int)\n",
        "        lon = (longitudes * self.div).astype(int)\n",
        "\n",
        "        discretizations = list(zip(lat, lon))\n",
        "\n",
        "        counter = Counter(discretizations)\n",
        "        if (vocab_size > 0):\n",
        "            pairs = counter.most_common(vocab_size)\n",
        "        else:\n",
        "            pairs = list(counter.items())\n",
        "\n",
        "        self.vocab = [keyword for keyword, count in pairs if count >= vocab_min_count]\n",
        "\n",
        "        self.indexes, self.data_idx, self.idx_data = buildIndexData(self.vocab, start_index)\n",
        "\n",
        "\n",
        "\n",
        "        return [self.data_idx.get(data, None) for data in discretizations], self.data_idx, self.idx_data\n",
        "\n",
        "\n",
        "\n",
        "    def transform(self, latitudes, longitudes):\n",
        "        lat = (latitudes * self.div).astype(int)\n",
        "        lon = (longitudes * self.div).astype(int)\n",
        "\n",
        "        discretizations = list(zip(lat, lon))\n",
        "        #indexes = [self.data_idx.get(data, None) for data in discretizations]\n",
        "        #return indexes\n",
        "        return discretizations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ETcm1_8ikKel",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class HourofDay(Discretize):\n",
        "    def fit_transform(self, created_at, start_index = 0):\n",
        "        indi = pd.DatetimeIndex(created_at)\n",
        "        discretizations = list(indi.hour)\n",
        "        self.indexes, self.data_idx, self.idx_data = buildIndexData(discretizations, start_index)\n",
        "        return self.indexes, self.data_idx, self.idx_data\n",
        "\n",
        "\n",
        "    def transform(self, created_at):\n",
        "        indi = pd.DatetimeIndex(created_at)\n",
        "        discretizations = list(indi.hour)\n",
        "        #indexes = [self.data_idx.get(data,None) for data in discretizations]\n",
        "        #return indexes\n",
        "        return discretizations\n",
        "\n",
        "class DayofWeak(Discretize):\n",
        "    def fit_transform(self, created_at, start_index = 0):\n",
        "        indi = pd.DatetimeIndex(created_at)\n",
        "\n",
        "        discretizations = list(indi.weekday)\n",
        "        self.indexes, self.data_idx, self.idx_data = buildIndexData(discretizations, start_index)\n",
        "        return self.indexes, self.data_idx, self.idx_data\n",
        "\n",
        "    def transform(self, created_at):\n",
        "        indi = pd.DatetimeIndex(created_at)\n",
        "        discretizations = list(indi.weekday)\n",
        "        indexes = [self.data_idx.get(data,None) for data in discretizations]\n",
        "        return indexes\n",
        "\n",
        "\n",
        "class HourofDay_DayofWeak(Discretize):\n",
        "    def fit_transform(self, created_at, start_index = 0):\n",
        "        indi = pd.DatetimeIndex(created_at)\n",
        "\n",
        "        discretizations = list(zip(indi.weekday, indi.hour))\n",
        "        self.indexes, self.data_idx, self.idx_data = buildIndexData(discretizations, start_index)\n",
        "        return self.indexes, self.data_idx, self.idx_data\n",
        "\n",
        "    def transform(self, created_at):\n",
        "        indi = pd.DatetimeIndex(created_at)\n",
        "\n",
        "        discretizations = list(zip(indi.weekday, indi.hour))\n",
        "        #indexes = [self.data_idx.get(data, None) for data in discretizations]\n",
        "        #return indexes        \n",
        "        return discretizations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "83kiVYqij4qA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class Indexer():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_transform(self,\n",
        "            filename,\n",
        "            #time_discretizer = HourofDay,\n",
        "            time_discretizer = HourofDay,\n",
        "                      \n",
        "            coor_discretizer = Round,\n",
        "            #represent_text = RepresentText,\n",
        "            dates_vocab_size = 0, dates_vocab_mincount = 0,\n",
        "            places_vocab_size = 0, places_vocab_mincount = 0,\n",
        "            words_vocab_size = 0, words_vocab_mincount = 0): #file_csv has columns created_at, latitude, longitude, text\n",
        "\n",
        "        #self.datapath = \"Data\" + sep\n",
        "        if (filename.split('.')[1] == 'csv'):\n",
        "            df = pd.read_csv(filename)\n",
        "        elif (filename.split('.')[1] == 'p'):\n",
        "            df = pd.read_pickle(filename)\n",
        "\n",
        "        self.time_discretizer = time_discretizer()\n",
        "        self.coor_discretizer = coor_discretizer(100)\n",
        "        #self.represent_text = represent_text()\n",
        "\n",
        "        #date_out, self.date_idx, self.idx_date = self.time_discretizer.fit_transform(df['created_at'], start_index = 0)\n",
        "        dates = self.time_discretizer.transform(df['created_at'])\n",
        "\n",
        "        #self.coor_out, self.coor_idx, self.idx_coor = self.coor_discretizer.fit_transform(df['latitude'], df['longitude'],start_index=max(self.date_out) + 1)\n",
        "\n",
        "        places = self.coor_discretizer.transform(df['latitude'], df['longitude'])\n",
        "\n",
        "        \n",
        "        texts = df['texts'].astype(str)\n",
        "        words = [word for list_words in texts for word in list_words.split()]\n",
        "        #print(len(texts))\n",
        "\n",
        "\n",
        "        counter_dates = Counter(dates)\n",
        "        if (dates_vocab_size > 0):\n",
        "            pairs = counter_dates.most_common(dates_vocab_size)\n",
        "        else:\n",
        "            pairs = list(counter_dates.items())\n",
        "        self.vocab_dates = set([date for date, count in pairs if count >= dates_vocab_mincount])\n",
        "\n",
        "\n",
        "        counter_places = Counter(places)\n",
        "        if (places_vocab_size > 0):\n",
        "            pairs = counter_places.most_common(places_vocab_size)\n",
        "        else:\n",
        "            pairs = list(counter_places.items())\n",
        "        self.vocab_places = set([place for place, count in pairs if count >= places_vocab_mincount])\n",
        "\n",
        "\n",
        "        counter_words = Counter(words)\n",
        "        if (words_vocab_size > 0):\n",
        "            pairs = counter_words.most_common(words_vocab_size)\n",
        "        else:\n",
        "            pairs = list(counter_words.items())\n",
        "\n",
        "        self.vocab_words = set([keyword for keyword, count in pairs if count >= words_vocab_mincount])\n",
        "\n",
        "        filtered_dates = set([i for i in range(len(dates)) if dates[i] in self.vocab_dates ])\n",
        "        filtered_places = set([i for i in range(len(places)) if places[i] in self.vocab_places])\n",
        "        filtered_words = set([i for i in range(len(texts)) if any([word in self.vocab_words for word in texts[i].split()]) ])\n",
        "\n",
        "        #print(len(filtered_dates))\n",
        "        #print(len(filtered_places))\n",
        "        #print(len(filtered_words))\n",
        "\n",
        "        filtered = list(filtered_dates.intersection(filtered_places).intersection(filtered_words))\n",
        "        #print(len(filtered))\n",
        "\n",
        "        dates = [dates[i] for i in filtered]\n",
        "        places = [places[i] for i in filtered]\n",
        "        texts = [texts[i] for i in filtered]\n",
        "\n",
        "\n",
        "        idxsdates, self.date2idx, self.idx2date = buildIndexData(dates, start_index=0)\n",
        "        idxsplaces, self.place2idx, self.idx2place = buildIndexData(places, start_index=max(idxsdates) + 1)\n",
        "\n",
        "        idxs, self.word2idx, self.idx2word = buildIndexData(self.vocab_words, start_index = max(idxsplaces) + 1)\n",
        "\n",
        "        idxstexts = []\n",
        "\n",
        "        for text in texts:\n",
        "            indexed_text = [self.word2idx[word] for word in text.split() if word in self.vocab_words]\n",
        "            idxstexts.append(indexed_text)\n",
        "\n",
        "        self.idx2item = {}\n",
        "        self.idx2item.update(self.idx2word)\n",
        "        self.idx2item.update(self.idx2place)\n",
        "        self.idx2item.update(self.idx2date)\n",
        "\n",
        "        self.item2idx = {}\n",
        "        self.item2idx.update(self.word2idx)\n",
        "        self.item2idx.update(self.place2idx)\n",
        "        self.item2idx.update(self.date2idx)\n",
        "\n",
        "        return list(zip(idxsdates,\n",
        "                             idxsplaces,\n",
        "                             idxstexts))\n",
        "\n",
        "\n",
        "    def transform(self, filename):\n",
        "        if (filename.split('.')[1] == 'csv'):\n",
        "            df = pd.read_csv( filename)\n",
        "        elif (filename.split('.')[1] == 'p'):\n",
        "            df = pd.read_pickle( filename)\n",
        "\n",
        "        dates = self.time_discretizer.transform(df['created_at'])\n",
        "        idxsdates = [self.date2idx.get(date, None) for date in dates]\n",
        "\n",
        "        places = self.coor_discretizer.transform(df['latitude'], df['longitude'])\n",
        "        idxsplaces = [self.place2idx.get(place, None) for place in places]\n",
        "\n",
        "        idxstexts = []\n",
        "        for text in df['texts'].astype(str):\n",
        "            indexed_text = [self.word2idx[word] for word in text.split() if word in self.vocab_words]\n",
        "            idxstexts.append(indexed_text)\n",
        "\n",
        "\n",
        "        full_list = list(zip(idxsdates,\n",
        "                             idxsplaces,\n",
        "                             idxstexts))\n",
        "        #print(len(full_list))\n",
        "        clean_list = [(x[0], x[1], x[2]) for x in full_list if ((x[0] != None) and (x[1] != None) and (x[2] != [])) ]\n",
        "        return clean_list\n",
        "\n",
        "\n",
        "    def Item2index(self, item):\n",
        "        return self.item2idx.get(item, -1)\n",
        "\n",
        "    def Index2item(self, index):\n",
        "        return self.idx2item.get(index, None)\n",
        "\n",
        "    def indexes(self):\n",
        "        return (self.coor_out[0], self.coor_out[-1], self.texts_out[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Nr0OFbBnUOj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5d0c345e-83c4-4130-b399-80be3a12fd34"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "indexerST = Indexer()\n",
        "trainST = indexerST.fit_transform(data+'tweets2016_2half.csv', dates_vocab_mincount=0, words_vocab_mincount=100, places_vocab_mincount=10)\n",
        "testST = indexerST.transform(data+'toy_2017_Jan.csv')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11 s, sys: 225 ms, total: 11.2 s\n",
            "Wall time: 11.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wO76vzQhnUSR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d10020c6-da70-46e9-aeed-a32a7fc85064"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "indexerLA = Indexer()\n",
        "trainLA = indexerLA.fit_transform(data+'tweetsLAtrain.csv', dates_vocab_mincount=0, words_vocab_mincount=100, places_vocab_mincount=10)\n",
        "testLA = indexerLA.transform(data+'tweetsLAtest.csv')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 40.9 s, sys: 768 ms, total: 41.7 s\n",
            "Wall time: 41.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ehoAepDonUWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "aff485bc-e2bd-4a6c-ebb1-e5e57e93def7"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "indexerNY = Indexer()\n",
        "trainNY = indexerNY.fit_transform(data+'tweetsNYtrain.csv', dates_vocab_mincount=0, words_vocab_mincount=100, places_vocab_mincount=10)\n",
        "testNY = indexerNY.transform(data+'tweetsNYtest.csv')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11.5 s, sys: 83.2 ms, total: 11.6 s\n",
            "Wall time: 11.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bbiGFbPwveHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "45799bae-1d59-4ab1-ddc7-1eca2fe22871"
      },
      "cell_type": "code",
      "source": [
        "t = torch.zeros([150,2,100])\n",
        "print(t.shape)\n",
        "print(torch.sum(t, dim=1).shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HMaTYvHhR6el",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "e = nn.Embedding(10, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Avlp8VaVSC__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "67e02135-3fbf-4a90-fe06-401a69ae126e"
      },
      "cell_type": "code",
      "source": [
        "a = e(torch.tensor([[1],[2]]))\n",
        "a"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.6092, -0.9798, -1.6091, -0.7121,  0.3037]],\n",
              "\n",
              "        [[-0.7773, -0.2515, -0.2223,  1.6871,  0.2284]]],\n",
              "       grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "kHTHUe5xSg-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "53ee8ee9-81d9-467d-e0ae-9adbe8a9b962"
      },
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "AUuLhISeVvvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4c1d601c-73d6-408a-e499-d7fb67c4cdc9"
      },
      "cell_type": "code",
      "source": [
        "c = torch.zeros(10)\n",
        "c.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "L1VwYzyQT_Ot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0a014639-f5f7-4002-c1a1-56a26afc37f3"
      },
      "cell_type": "code",
      "source": [
        "t = torch.ones([3,2])\n",
        "v = torch.tensor([[2.0],[1.5],[3.0]])\n",
        "print(v.shape)\n",
        "print(t.shape)\n",
        "z = v * t\n",
        "z.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1])\n",
            "torch.Size([3, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "TqGqoWKlBhfV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "f33cdabc-192b-4cea-ca60-498a6856a8e2"
      },
      "cell_type": "code",
      "source": [
        "emb = nn.Embedding(10, 5)\n",
        "emb.weight.data[0] = torch.zeros(5)\n",
        "emb.weight.data"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0103,  0.9837,  0.8793, -0.9962, -0.8313],\n",
              "        [-0.4610, -0.5601,  0.3956, -0.9823,  1.3264],\n",
              "        [ 0.8547, -0.6540,  0.7317, -1.4344, -0.5008],\n",
              "        [ 0.1716, -0.1600, -0.5047, -1.4746, -1.0412],\n",
              "        [ 0.7323, -1.0483, -0.4709,  0.2911,  1.9907],\n",
              "        [-0.9247, -0.9301,  0.8165, -0.9135,  0.2053],\n",
              "        [ 0.3051,  0.5357, -0.4312,  0.1573,  1.2540],\n",
              "        [ 1.3275, -0.4954, -1.9804,  1.7986,  0.1018],\n",
              "        [ 0.3400, -0.6447, -0.2870,  3.3212, -0.4021]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "fKDUM7jvCQJb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Models"
      ]
    },
    {
      "metadata": {
        "id": "7S5_mCHKVqul",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Embed(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(Embed, self).__init__()\n",
        "        self.embed_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    def forward(self, input):\n",
        "        return self.embedding(input)\n",
        "        \n",
        "\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, embed, batch_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.embedding = embed\n",
        "        self.hidden_size = hidden_size\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, self.batch_size, -1)\n",
        "        #print(input)\n",
        "        #print(embedded)\n",
        "        embedded = F.relu(embedded)\n",
        "        \n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.batch_size, self.hidden_size, device=device)\n",
        "    \n",
        "      \n",
        "class DecoderRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, embed, range_times, range_coors, range_words, batch_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = embed\n",
        "        self.hidden_size = hidden_size\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        self.linearTimes = nn.Linear(hidden_size, max(range_times)-min(range_times)+1, bias=False)\n",
        "        self.linearCoors = nn.Linear(hidden_size, max(range_coors)-min(range_coors)+1, bias=False)\n",
        "        self.linearWords = nn.Linear(hidden_size, max(range_words)-min(range_words)+1, bias=False)\n",
        "        \n",
        "    def forward(self, inputs, hidden, target):\n",
        "      \n",
        "        #embeds = self.embedding(inputs).view(1, 1, -1)\n",
        "        \n",
        "        \n",
        "        \n",
        "        #embeds = embeds.view((self.batch_size,-1))\n",
        "        \n",
        "        \n",
        "        if target == 0:\n",
        "            out = self.linearTimes(hidden)\n",
        "            #print(hidden)\n",
        "            #print(out)\n",
        "\n",
        "            log_probs = self.softmax(out.view(self.batch_size,-1))\n",
        "            #print(log_probs)\n",
        "            return log_probs#.view(log_probs.numel())  \n",
        "\n",
        "        elif target == 1:\n",
        "            out = self.linearCoors(hidden)\n",
        "            log_probs = self.softmax(out.view(self.batch_size,-1))\n",
        "\n",
        "            return log_probs#.view(log_probs.numel())            \n",
        "                        \n",
        "\n",
        "        else:#target in range_words\n",
        "          \n",
        "            embeds = self.embedding(inputs).view(1, self.batch_size, -1)\n",
        "            #print(inputs.shape)\n",
        "            #print(hidden.shape)\n",
        "            embeds = F.relu(embeds)\n",
        "            output, hidden = self.gru(embeds, hidden)\n",
        "            #print(output.shape)\n",
        "          \n",
        "            output = self.softmax(self.linearWords(output[0]))\n",
        "            return output, hidden\n",
        "        \n",
        "      \n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.batch_size, self.hidden_size, device=device)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AJH1LJyznUgU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SimpleRNN():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def transform_as_nparray(self, tuples_train):\n",
        "        output = []\n",
        "        self.max_length = 0\n",
        "        for (aux_date_idx, aux_coor_idx, text) in tuples_train:\n",
        "            if(len(text) > self.max_length):\n",
        "                self.max_length = len(text)\n",
        "            \n",
        "            for word_numb in text:\n",
        "                _tuple = (aux_date_idx, aux_coor_idx, word_numb)\n",
        "                output.append(_tuple)\n",
        "        print(self.max_length)\n",
        "        return np.array(output)\n",
        "    \n",
        "    def transform_as_seq(self, tuples_train):\n",
        "        output = {0:[], 1:[], 2:[]}\n",
        "        for _tuple in tuples_train:\n",
        "                _tuple2 = _tuple[2]\n",
        "                for i in range(self.max_length-len(_tuple2)):\n",
        "                    _tuple2.append(self.padding)\n",
        "                \n",
        "                tuple = ([_tuple[0]],[_tuple[1]],_tuple[2])\n",
        "                    \n",
        "                for i in range(3):\n",
        "                    target = [t-self.min_ranges[i] for t in tuple[i]]\n",
        "                     \n",
        "                    data = [k for j in range(3) if (j != i) for k in tuple[j]]\n",
        "                    output[i].append((data, target))\n",
        "        \n",
        "        return output\n",
        "    \n",
        "    \n",
        "    def next_batch(self):\n",
        "        type_target = random.sample(range(3),1)[0]\n",
        "        examples = random.sample(self.seq_train[type_target], self.batch_size)\n",
        "        data = [data for data,target in examples]\n",
        "        targets = [target for data,target in examples]\n",
        "        if (type_target != 2):        \n",
        "            return np.array(data).transpose(),np.array(targets), type_target\n",
        "        else:\n",
        "            return np.array(data).transpose(),np.array(targets).transpose(), type_target\n",
        "          \n",
        "    \n",
        "    def get_ranks(self, test, predictor, predict_type = 'w'):\n",
        "        self.predict_type = predict_type\n",
        "        noiseList = np.random.choice(len(test), self.fake_num*len(test)).tolist()\n",
        "        count = 5\n",
        "        for example in test:\n",
        "\n",
        "            scores = []\n",
        "            score = predictor.predict(example[0], example[1], example[2])\n",
        "            scores.append(score)\n",
        "\n",
        "\n",
        "            for i in range(self.fake_num):\n",
        "                noise = test[noiseList.pop()]\n",
        "                if self.predict_type == 't':\n",
        "                    noise_score = predictor.predict(noise[0], example[1], example[2])\n",
        "                elif self.predict_type=='l':\n",
        "                    noise_score = predictor.predict(example[0], noise[1], example[2])\n",
        "                elif self.predict_type=='w':\n",
        "                    noise_score = predictor.predict(example[0], example[1], noise[2])\n",
        "                scores.append(noise_score)\n",
        "            scores.sort()\n",
        "    \n",
        "    def fit_batch(self, tuples_train, embedding_dims, num_epochs = 1, hidden_size=100, batch_size=10):\n",
        "        \n",
        "        xytrain = self.transform_as_nparray(tuples_train)\n",
        "        vocabulary_size = int(max(list(xytrain[:, -1]))) + 1\n",
        "        \n",
        "        self.padding = vocabulary_size\n",
        "        vocabulary_size += 1\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        \n",
        "        range_times = range(int(max(list(xytrain[:, -3]))) + 1)\n",
        "        range_coors = range(int(max(list(xytrain[:, -3]))) + 1, int(max(list(xytrain[:, -2]))) + 1)\n",
        "        range_words = range(int(max(list(xytrain[:, -2]))) + 1, vocabulary_size)\n",
        "        self.min_ranges = [min(range_times), min(range_coors), min(range_words)]\n",
        "        print(len(tuples_train))\n",
        "        #tuples_train = tuples_train[:5000]\n",
        "        numexamples = len(tuples_train)\n",
        "        \n",
        "        self.seq_train = self.transform_as_seq(tuples_train)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        losses = []\n",
        "        loss_function = nn.NLLLoss()\n",
        "      \n",
        "        embed = Embed(vocabulary_size, embedding_dims).to(device)\n",
        "        optimizer_emb = optim.Adam(embed.parameters(), lr=0.001)\n",
        "        \n",
        "        encoder = EncoderRNN(embedding_dims, hidden_size, embed, batch_size).to(device)\n",
        "        optimizer_enc = optim.Adam(encoder.parameters(), lr=0.001)\n",
        "        \n",
        "        decoder = DecoderRNN(embedding_dims, hidden_size, embed, range_times, range_coors, range_words, batch_size).to(device)\n",
        "        optimizer_dec = optim.Adam(decoder.parameters(), lr=0.001)\n",
        "        \n",
        "        \n",
        "    \n",
        "        for epoch in range(num_epochs):\n",
        "            total_loss = 0\n",
        "            #for _ in range(3):\n",
        "            for _ in range(3*numexamples//self.batch_size):\n",
        "                \n",
        "                input_seq, target, type_target = self.next_batch()\n",
        "                \n",
        "                input_seq = torch.tensor(input_seq, device=device)\n",
        "                target = torch.tensor(target, device=device)\n",
        "                \n",
        "                optimizer_dec.zero_grad()\n",
        "                optimizer_enc.zero_grad() \n",
        "                #optimizer_emb.zero_grad()\n",
        "                \n",
        "                loss = 0\n",
        "                input_length = input_seq.shape[0]\n",
        "                \n",
        "                #encoder_outputs = torch.zeros(input_length, encoder.hidden_size, device=device)\n",
        "                \n",
        "                encoder_hidden = encoder.initHidden()\n",
        "                for ei in range(input_length):\n",
        "                    encoder_output, encoder_hidden = encoder(input_seq[ei], encoder_hidden)\n",
        "                    #encoder_outputs[ei] = encoder_output[0, 0]\n",
        "                \n",
        "                decoder_hidden = encoder_hidden\n",
        "                decoder_input = input_seq[-1]#[input_length-1].view(1, self.batch_size, -1)\n",
        "                \n",
        "                if (type_target == 2):\n",
        "                    target_length = input_seq.shape[0]\n",
        "                    decoder_outputs = torch.zeros(target_length, decoder.hidden_size, device=device)\n",
        "                    target_seq = torch.tensor(target, device=device)\n",
        "                  \n",
        "                  \n",
        "                    for di in range(target_length):\n",
        "                        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, type_target)\n",
        "                        loss += loss_function(decoder_output, target_seq[di])\n",
        "                        decoder_input = target[di] \n",
        "                        decoder_outputs[di] = decoder_output[0, 0]\n",
        "                else:\n",
        "                    log_probs = decoder(decoder_input, decoder_hidden, type_target)\n",
        "                  \n",
        "                    loss = loss_function(log_probs, target.view(target.numel()))\n",
        "                \n",
        "                loss.backward()\n",
        "                total_loss += loss.item()\n",
        "                optimizer_dec.step()\n",
        "                optimizer_enc.step() \n",
        "                #optimizer_emb.step()\n",
        "                \n",
        "                encoder_hidden = encoder_hidden.detach()\n",
        "            #if epoch % (num_epochs//10 +1) == 0:\n",
        "            #  print(total_loss/numexamples)\n",
        "            print(total_loss/numexamples)\n",
        "        self.embed = embed\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "    \n",
        "    def predict(self, tuples_test, batch_test=1000, predict_type = 't'):\n",
        "        batch_test = self.batch_size\n",
        "        self.seq_test = self.transform_as_seq(tuples_test)\n",
        "        print(len(self.seq_test[0]))\n",
        "        \n",
        "        \n",
        "        self.predict_type = predict_type\n",
        "        convert = {'w':2,'l':1,'t':0}\n",
        "        \n",
        "        encoder = self.encoder\n",
        "        decoder = self.decoder\n",
        "        \n",
        "        type_target = convert[predict_type]\n",
        "        multiple  = (len(self.seq_test[type_target])//batch_test)*batch_test\n",
        "        #multiple = batch_test\n",
        "        it = iter(self.seq_test[type_target][:multiple])\n",
        "        results = []\n",
        "        results_targets = []\n",
        "        while True:\n",
        "            #examplestest = list(itertools.islice(it, 10))\n",
        "            #print(examplestest)\n",
        "            \n",
        "            examples = list(itertools.islice(it, batch_test))\n",
        "            if examples:\n",
        "                \n",
        "                data = [data for data,target in examples]\n",
        "                targets = [target for data,target in examples]\n",
        "\n",
        "                if (type_target != 2):        \n",
        "                    input_seq = np.array(data).transpose()\n",
        "                    target = np.array(targets)\n",
        "                \n",
        "                else:\n",
        "                    input_seq = np.array(data).transpose()\n",
        "                    target = np.array(targets).transpose()\n",
        "                #print(input_seq)\n",
        "                input_seq = torch.tensor(input_seq, device=device)\n",
        "                target = torch.tensor(target, device=device)\n",
        "\n",
        "                input_length = input_seq.shape[0]\n",
        "\n",
        "                encoder_hidden = encoder.initHidden()\n",
        "                for ei in range(input_length):\n",
        "                    encoder_output, encoder_hidden = encoder(input_seq[ei], encoder_hidden)\n",
        "                    #encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "                decoder_hidden = encoder_hidden\n",
        "                decoder_input = encoder_output#[input_length-1].view(1, self.batch_size, -1)\n",
        "\n",
        "                if (type_target == 2):\n",
        "                    target_length = input_seq.shape[0]\n",
        "                    decoder_outputs = torch.zeros(target_length, decoder.hidden_size, device=device)\n",
        "                    target_seq = torch.tensor(target, device=device)\n",
        "\n",
        "\n",
        "                    for di in range(target_length):\n",
        "                        input = target_seq[di]\n",
        "                        decoder_output, decoder_hidden = decoder(input, decoder_hidden, type_target)\n",
        "                        loss += loss_function(decoder_output, input)\n",
        "                        #decoder_input = target[di] \n",
        "                        decoder_outputs[di] = decoder_output[0, 0]\n",
        "                else:\n",
        "                    log_probs = decoder(decoder_input, decoder_hidden, type_target)\n",
        "                    results.append(log_probs)\n",
        "                    #r = range(log_probs.shape[0])\n",
        "                    #z = zip(r,targets)\n",
        "                    #l = list(z)\n",
        "                    #torch.tensor(l)\n",
        "                    results_targets.append(targets)\n",
        "\n",
        "                encoder_hidden = encoder_hidden.detach()\n",
        "            \n",
        "            else:\n",
        "                break\n",
        "   \n",
        "        return results, results_targets\n",
        "        \n",
        "        \n",
        "        \n",
        "    def mrr(self,results,results_targets):\n",
        "        \n",
        "        all_scores = []\n",
        "        all_score = []\n",
        "        fake = 10\n",
        "        for i in range(len(results)):\n",
        "            for j in range(results[i].shape[0]):\n",
        "                all_score.append(results[i][j][results_targets[i][j]].item())\n",
        "                l = [results[i][j][k].item()  for k in random.choices(range(results[i].shape[1]),k=fake)]\n",
        "                l.append(results[i][j][results_targets[i][j]].item())\n",
        "                l.sort()\n",
        "                all_scores.append(l)\n",
        "        \n",
        "        \n",
        "        r = []\n",
        "        for i in range(len(all_score)):\n",
        "            score = all_score[i]\n",
        "            scores = all_scores[i]\n",
        "            rank = len(scores)+1-(bisect.bisect_left(scores,score)+bisect.bisect_right(scores,score)+1)/2.0\n",
        "            r.append(rank)\n",
        "    \n",
        "        reciprocal_ranks = [1/rank for rank in r]\n",
        "        mrr = sum(reciprocal_ranks)/len(reciprocal_ranks)\n",
        "        mr = sum(r)/len(r)\n",
        "        return round(mrr,4), round(mr,4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ANIyV1JOLfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "a6e21310-70a1-4fd2-e0c2-732c8011e4ce"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "translate = {'w':'Text','l':'Location','t':'Time'}\n",
        "trainsets = [trainST, trainLA, trainNY]\n",
        "testsets = [testST, testLA, testNY]\n",
        "namesets = ['Santiago','LA','NY']\n",
        "#results = {'Model':[],'Dataset':[],  'Text':[], 'Location':[],'Time':[]}\n",
        "results = {'Model':[],'Dataset':[], 'Location':[],'Time':[]}\n",
        "\n",
        "for train,test,name in list(zip(trainsets, testsets, namesets))[:1]:\n",
        "    \n",
        "    dims = [100]\n",
        "    batchs = [250]\n",
        "    \n",
        "    \n",
        "    for dim in dims:\n",
        "        for batch in batchs:\n",
        "            model = SimpleRNN()\n",
        "            model.fit_batch(train, embedding_dims=dim, num_epochs=7, hidden_size=dim, batch_size=batch)\n",
        "\n",
        "            for predict_type in 'lt':\n",
        "                resultsp, results_targets = model.predict(test, predict_type=predict_type)\n",
        "                mrr1 = model.mrr(resultsp, results_targets)[0]\n",
        "                print(mrr1)\n",
        "                print(\"mrr\")\n",
        "\n",
        "                results[translate[predict_type]].append(mrr1)\n",
        "\n",
        "            results['Dataset'].append(name)\n",
        "\n",
        "            results['Model'].append(str(type(model))+'_'+str())\n",
        "\n",
        "            df = pd.DataFrame(results)\n",
        "\n",
        "            df.to_csv('resultsemb2.df')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "251115\n",
            "0.08206666863392116\n",
            "0.07065262980489889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iM6I49Mkp8hX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2428
        },
        "outputId": "5b51f09b-6c20-4397-9105-850ccbc7f94a"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "translate = {'w':'Text','l':'Location','t':'Time'}\n",
        "trainsets = [trainST, trainLA, trainNY]\n",
        "testsets = [testST, testLA, testNY]\n",
        "namesets = ['Santiago','LA','NY']\n",
        "#results = {'Model':[],'Dataset':[],  'Text':[], 'Location':[],'Time':[]}\n",
        "results = {'Model':[],'Dataset':[], 'Location':[],'Time':[]}\n",
        "\n",
        "for train,test,name in list(zip(trainsets, testsets, namesets))[2:]:\n",
        "    \n",
        "    dims = [50,100]\n",
        "    \n",
        "    \n",
        "    \n",
        "    batchs = [1000,500,250,100]\n",
        "    \n",
        "    \n",
        "    for dim in dims:\n",
        "        for batch in batchs:\n",
        "            model = SimpleRNN()\n",
        "            model.fit_batch(train, embedding_dims=dim, num_epochs=40, hidden_size=dim, batch_size=batch)\n",
        "\n",
        "            for predict_type in 'lt':\n",
        "                resultsp, results_targets = model.predict(test, predict_type=predict_type)\n",
        "                mrr1 = model.mrr(resultsp, results_targets)[0]\n",
        "                print(mrr1)\n",
        "                print(\"mrr\")\n",
        "\n",
        "                results[translate[predict_type]].append(mrr1)\n",
        "\n",
        "            results['Dataset'].append(name)\n",
        "\n",
        "            results['Model'].append(str(type(model))+'_'+str())\n",
        "\n",
        "            df = pd.DataFrame(results)\n",
        "\n",
        "            df.to_csv('resultsemb2.df')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n",
            "317707\n",
            "0.014784225208567564\n",
            "0.009671279903598395\n",
            "0.008829599864243146\n",
            "0.008529818023160296\n",
            "0.008030825267029962\n",
            "0.007937913273384247\n",
            "0.007564301380011189\n",
            "0.007681143929259549\n",
            "0.007110372002230767\n",
            "0.00742339736437141\n",
            "0.007242952342258002\n",
            "0.007393056970974127\n",
            "0.007092512420357726\n",
            "0.0073772167003076225\n",
            "0.007148606751725535\n",
            "0.0071383064724915195\n",
            "0.007182187239811504\n",
            "0.007275316066649539\n",
            "0.007184540687862065\n",
            "0.006851347661944127\n",
            "0.007012828193746939\n",
            "0.006870763007013571\n",
            "0.006773727100554582\n",
            "0.0070534727674710996\n",
            "0.0069991381044311055\n",
            "0.007090403544054323\n",
            "0.007004500174339516\n",
            "0.006939810087970884\n",
            "0.006769300000126148\n",
            "0.006692421043047152\n",
            "0.007051509418620284\n",
            "0.007059902679860649\n",
            "0.006967499979690332\n",
            "0.006744425429981232\n",
            "0.0068245530169767825\n",
            "0.006968659727145203\n",
            "0.007071946683234799\n",
            "0.0068362002728012804\n",
            "0.006796474252551612\n",
            "0.006916968281852082\n",
            "77746\n",
            "0.9298\n",
            "mrr\n",
            "77746\n",
            "0.4281\n",
            "mrr\n",
            "14\n",
            "317707\n",
            "0.025351865777940446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-57e9c021945f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'translate = {\\'w\\':\\'Text\\',\\'l\\':\\'Location\\',\\'t\\':\\'Time\\'}\\ntrainsets = [trainST, trainLA, trainNY]\\ntestsets = [testST, testLA, testNY]\\nnamesets = [\\'Santiago\\',\\'LA\\',\\'NY\\']\\n#results = {\\'Model\\':[],\\'Dataset\\':[],  \\'Text\\':[], \\'Location\\':[],\\'Time\\':[]}\\nresults = {\\'Model\\':[],\\'Dataset\\':[], \\'Location\\':[],\\'Time\\':[]}\\n\\nfor train,test,name in list(zip(trainsets, testsets, namesets))[2:]:\\n    \\n    dims = [50,100]\\n    \\n    \\n    \\n    batchs = [1000,500,250,100]\\n    \\n    \\n    for dim in dims:\\n        for batch in batchs:\\n            model = SimpleRNN()\\n            model.fit_batch(train, embedding_dims=dim, num_epochs=40, hidden_size=dim, batch_size=batch)\\n\\n            for predict_type in \\'lt\\':\\n                resultsp, results_targets = model.predict(test, predict_type=predict_type)\\n                mrr1 = model.mrr(resultsp, results_targets)[0]\\n                print(mrr1)\\n                print(\"mrr\")\\n\\n                results[translate[predict_type]].append(mrr1)\\n\\n            results[\\'Dataset\\'].append(name)\\n\\n            results[\\'Model\\'].append(str(type(model))+\\'_\\'+str())\\n\\n            df = pd.DataFrame(results)\\n\\n            df.to_csv(\\'resultsemb2.df\\')'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-36a23ebd3959>\u001b[0m in \u001b[0;36mfit_batch\u001b[0;34m(self, tuples_train, embedding_dims, num_epochs, hidden_size, batch_size)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mei\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                     \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                     \u001b[0;31m#encoder_outputs[ei] = encoder_output[0, 0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-465edd3192e6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m#print(input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print(embedded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-465edd3192e6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    108\u001b[0m         return F.embedding(\n\u001b[1;32m    109\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "II7YVeGMd3To",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3244
        },
        "outputId": "43cba07e-8606-4d2b-c317-a552a29dbcc1"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "translate = {'w':'Text','l':'Location','t':'Time'}\n",
        "trainsets = [trainST, trainLA, trainNY]\n",
        "testsets = [testST, testLA, testNY]\n",
        "namesets = ['Santiago','LA','NY']\n",
        "#results = {'Model':[],'Dataset':[],  'Text':[], 'Location':[],'Time':[]}\n",
        "results = {'Model':[],'Dataset':[], 'Location':[],'Time':[]}\n",
        "\n",
        "for train,test,name in list(zip(trainsets, testsets, namesets))[2:]:\n",
        "    \n",
        "    dims = [50,100]\n",
        "    \n",
        "    \n",
        "    \n",
        "    batchs = [1000,500,250,100]\n",
        "    \n",
        "    \n",
        "    for dim in dims:\n",
        "        for batch in batchs:\n",
        "            model = SimpleRNN()\n",
        "            model.fit_batch(train, embedding_dims=dim, num_epochs=10, hidden_size=dim, batch_size=batch)\n",
        "\n",
        "            for predict_type in 'lt':\n",
        "                resultsp, results_targets = model.predict(test, predict_type=predict_type)\n",
        "                mrr1 = model.mrr(resultsp, results_targets)[0]\n",
        "                print(mrr1)\n",
        "                print(\"mrr\")\n",
        "\n",
        "                results[translate[predict_type]].append(mrr1)\n",
        "\n",
        "            results['Dataset'].append(name)\n",
        "\n",
        "            results['Model'].append(str(type(model))+'_'+str())\n",
        "\n",
        "            df = pd.DataFrame(results)\n",
        "\n",
        "            df.to_csv('resultsemb2.df')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n",
            "317707\n",
            "0.011613858806086126\n",
            "0.00720379506351147\n",
            "0.006666679903151712\n",
            "0.005977282488135828\n",
            "0.005777304285767592\n",
            "0.005420811765169754\n",
            "0.005332260364128921\n",
            "0.005289745244325139\n",
            "0.00536077715498667\n",
            "0.00503271908312541\n",
            "77746\n",
            "0.9265\n",
            "mrr\n",
            "77746\n",
            "0.4118\n",
            "mrr\n",
            "14\n",
            "317707\n",
            "0.020096860270693278\n",
            "0.013482907833978975\n",
            "0.01203330023458646\n",
            "0.011510590771188668\n",
            "0.010767187888385857\n",
            "0.010640679807543662\n",
            "0.010295348789665742\n",
            "0.01019478900879058\n",
            "0.009933253941012613\n",
            "0.01017891483327144\n",
            "77746\n",
            "0.9283\n",
            "mrr\n",
            "77746\n",
            "0.4146\n",
            "mrr\n",
            "14\n",
            "317707\n",
            "0.03381158618253653\n",
            "0.02386464756136601\n",
            "0.021793696180801667\n",
            "0.020861264540544575\n",
            "0.0204247453904059\n",
            "0.019747836933905066\n",
            "0.019525646088226756\n",
            "0.019155810782660373\n",
            "0.01923723460010268\n",
            "0.018833513446348725\n",
            "77746\n",
            "0.9314\n",
            "mrr\n",
            "77746\n",
            "0.4153\n",
            "mrr\n",
            "14\n",
            "317707\n",
            "0.07295304885134635\n",
            "0.05499347818580456\n",
            "0.05080554072981617\n",
            "0.05039433144155547\n",
            "0.04873439414689478\n",
            "0.04837037368766092\n",
            "0.047272187548358324\n",
            "0.04686696527477374\n",
            "0.04736675702799198\n",
            "0.0461671987350877\n",
            "77746\n",
            "0.9329\n",
            "mrr\n",
            "77746\n",
            "0.4145\n",
            "mrr\n",
            "14\n",
            "317707\n",
            "0.009466790618359167\n",
            "0.006228731454284359\n",
            "0.00544109129798552\n",
            "0.005254202170383235\n",
            "0.004844412707145178\n",
            "0.004618976639765925\n",
            "0.004663847418683699\n",
            "0.004741298387493693\n",
            "0.004569860915490296\n",
            "0.004570828939969408\n",
            "77746\n",
            "0.9362\n",
            "mrr\n",
            "77746\n",
            "0.4164\n",
            "mrr\n",
            "14\n",
            "317707\n",
            "0.016540339226163842\n",
            "0.011236634850640963\n",
            "0.010309070298721162\n",
            "0.009823467890638777\n",
            "0.00950625380788407\n",
            "0.009217693881622378\n",
            "0.00888840773299731\n",
            "0.008959162021150406\n",
            "0.008698762127025797\n",
            "0.008594690885834587\n",
            "77746\n",
            "0.9396\n",
            "mrr\n",
            "77746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-066d8b4c2786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'translate = {\\'w\\':\\'Text\\',\\'l\\':\\'Location\\',\\'t\\':\\'Time\\'}\\ntrainsets = [trainST, trainLA, trainNY]\\ntestsets = [testST, testLA, testNY]\\nnamesets = [\\'Santiago\\',\\'LA\\',\\'NY\\']\\n#results = {\\'Model\\':[],\\'Dataset\\':[],  \\'Text\\':[], \\'Location\\':[],\\'Time\\':[]}\\nresults = {\\'Model\\':[],\\'Dataset\\':[], \\'Location\\':[],\\'Time\\':[]}\\n\\nfor train,test,name in list(zip(trainsets, testsets, namesets))[2:]:\\n    \\n    dims = [50,100]\\n    \\n    \\n    \\n    batchs = [1000,500,250,100]\\n    \\n    \\n    for dim in dims:\\n        for batch in batchs:\\n            model = SimpleRNN()\\n            model.fit_batch(train, embedding_dims=dim, num_epochs=10, hidden_size=dim, batch_size=batch)\\n\\n            for predict_type in \\'lt\\':\\n                resultsp, results_targets = model.predict(test, predict_type=predict_type)\\n                mrr1 = model.mrr(resultsp, results_targets)[0]\\n                print(mrr1)\\n                print(\"mrr\")\\n\\n                results[translate[predict_type]].append(mrr1)\\n\\n            results[\\'Dataset\\'].append(name)\\n\\n            results[\\'Model\\'].append(str(type(model))+\\'_\\'+str())\\n\\n            df = pd.DataFrame(results)\\n\\n            df.to_csv(\\'resultsemb2.df\\')'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-36a23ebd3959>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, tuples_test, batch_test, predict_type)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mei\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                     \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m                     \u001b[0;31m#encoder_outputs[ei] = encoder_output[0, 0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-b6c7bcc2370d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print(embedded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hx, batch_sizes)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvariable_length\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             dropout_ts)\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oEd1wP2goxEi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "7463e22f-8cc2-4a8e-c2b2-b623e8a0365b"
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Location</th>\n",
              "      <th>Model</th>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NY</td>\n",
              "      <td>0.3437</td>\n",
              "      <td>&lt;class '__main__.SimpleRNN'&gt;_</td>\n",
              "      <td>0.3024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Dataset  Location                          Model    Time\n",
              "0      NY    0.3437  <class '__main__.SimpleRNN'>_  0.3024"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "9D-0C_9Kt1oc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}