{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Represent.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/juglar-diaz/STTD/blob/master/Represent.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "R3QjBnH6lktK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LJWrJduhlnI-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jGPfqOgRnsBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "10591bb9-c8cd-4b20-b714-989918177d0c"
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "!pip3 install torch torchvision"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 26kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5a1b6000 @  0x7fb97dcc71c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 17.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/24/f53ff6b61b3d728b90934bddb4f03f8ab584a7f49299bf3bde56e2952612/Pillow-5.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.2.0 torch-0.4.1 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lboU3CzKkHsc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torch.functional as F\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import itertools\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "torch.manual_seed(1)\n",
        "\n",
        "\n",
        "import pickle\n",
        "\n",
        "import os\n",
        "sep = os.sep\n",
        "import os.path\n",
        "\n",
        "data = \"\"\n",
        "import pandas as pd\n",
        "import bisect\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "id7ExeAEnvbv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    inGPU = True\n",
        "    _type = torch.cuda.FloatTensor\n",
        "    _typelong = torch.cuda.LongTensor\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    inGPU = False\n",
        "    _type = torch.FloatTensor\n",
        "    _typelong = torch.LongTensor\n",
        "    device = torch.device(\"cuda\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s6m5UOXClc5v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Data"
      ]
    },
    {
      "metadata": {
        "id": "Nrks3-MplPnI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "exchangedrive = drive.CreateFile({'id':'1cMCzlvTMlUPgaYaUIdlMVtTpp8r10GnX'})\n",
        "exchangedrive.GetContentFile('robosclean.p')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fqinedc4lvh2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "exchangedrive = drive.CreateFile({'id':'1A5Wa6LiaGs8XeW2S2qjGbcoSSlsMGW97'})\n",
        "exchangedrive.GetContentFile('tweetsLAtrain.csv')\n",
        "exchangedrive = drive.CreateFile({'id':'1CrUCS7oWzdvYoFwtWgikiGkDAu6w3dOF'})\n",
        "exchangedrive.GetContentFile('tweetsLAtest.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYQvo_-Alvl_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "exchangedrive = drive.CreateFile({'id':'1NuSVM7-h0CCRtzi0woM4h5tVd6T7JO2C'})\n",
        "exchangedrive.GetContentFile('tweetsNYtrain.csv')\n",
        "exchangedrive = drive.CreateFile({'id':'1UYZY0sh1-Q8MIofMAHDGaNKv8cfDA0ui'})\n",
        "exchangedrive.GetContentFile('tweetsNYtest.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w5iLxHb8lvqa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "exchangedrive = drive.CreateFile({'id':'1Jv19eJTZwsZWEA_rUudvKwcn1TS-DFBa'})\n",
        "exchangedrive.GetContentFile('tweets2016_2half.csv')\n",
        "exchangedrive = drive.CreateFile({'id':'1E8WlhOXb3tfQbLUpizx7QXzeydv57eXN'})\n",
        "exchangedrive.GetContentFile('toy_2017_Jan.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "42Nlwku5krUZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def buildIndexData(list_elements, start_index = 0):\n",
        "\n",
        "    idx2data = {index + start_index: discretization for index, discretization in enumerate(set(list_elements))}\n",
        "\n",
        "    data2idx = {discretization: index for index, discretization in idx2data.items()}\n",
        "\n",
        "    indexes = [data2idx[element] for element in list_elements]\n",
        "\n",
        "    return indexes, data2idx, idx2data\n",
        "\n",
        "\n",
        "class Discretize:\n",
        "    def fit_transform(self):\n",
        "        pass\n",
        "\n",
        "    def transform(self):\n",
        "        pass\n",
        "\n",
        "    def updateIndexes(self, indexes, star_index):\n",
        "        map_indexes = {value:counter+star_index for counter, value in enumerate(set(indexes))}\n",
        "\n",
        "\n",
        "        new_indexes = [map_indexes[index] for index in indexes]\n",
        "\n",
        "        idx2data = {map_indexes[index]:self.idx_data[index] for index in set(indexes)}\n",
        "        data2idx = {val:key for (key, val) in idx2data.items()}\n",
        "\n",
        "        self.idx_data = idx2data\n",
        "        self.data_idx = data2idx\n",
        "\n",
        "        return new_indexes\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WpcjzVxBkKbS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Round(Discretize):\n",
        "    def __init__(self, div= 10):\n",
        "        self.div= div\n",
        "\n",
        "    def fit_transform(self, latitudes, longitudes, start_index = 0, vocab_size = -1, vocab_min_count=0):\n",
        "        lat = (latitudes * self.div).astype(int)\n",
        "        lon = (longitudes * self.div).astype(int)\n",
        "\n",
        "        discretizations = list(zip(lat, lon))\n",
        "\n",
        "        counter = Counter(discretizations)\n",
        "        if (vocab_size > 0):\n",
        "            pairs = counter.most_common(vocab_size)\n",
        "        else:\n",
        "            pairs = list(counter.items())\n",
        "\n",
        "        self.vocab = [keyword for keyword, count in pairs if count >= vocab_min_count]\n",
        "\n",
        "        self.indexes, self.data_idx, self.idx_data = buildIndexData(self.vocab, start_index)\n",
        "\n",
        "\n",
        "\n",
        "        return [self.data_idx.get(data, None) for data in discretizations], self.data_idx, self.idx_data\n",
        "\n",
        "\n",
        "\n",
        "    def transform(self, latitudes, longitudes):\n",
        "        lat = (latitudes * self.div).astype(int)\n",
        "        lon = (longitudes * self.div).astype(int)\n",
        "\n",
        "        discretizations = list(zip(lat, lon))\n",
        "        #indexes = [self.data_idx.get(data, None) for data in discretizations]\n",
        "        #return indexes\n",
        "        return discretizations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ETcm1_8ikKel",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class HourofDay(Discretize):\n",
        "    def fit_transform(self, created_at, start_index = 0):\n",
        "        indi = pd.DatetimeIndex(created_at)\n",
        "        discretizations = list(indi.hour)\n",
        "        self.indexes, self.data_idx, self.idx_data = buildIndexData(discretizations, start_index)\n",
        "        return self.indexes, self.data_idx, self.idx_data\n",
        "\n",
        "\n",
        "    def transform(self, created_at):\n",
        "        indi = pd.DatetimeIndex(created_at)\n",
        "        discretizations = list(indi.hour)\n",
        "        #indexes = [self.data_idx.get(data,None) for data in discretizations]\n",
        "        #return indexes\n",
        "        return discretizations\n",
        "\n",
        "class DayofWeak(Discretize):\n",
        "    def fit_transform(self, created_at, start_index = 0):\n",
        "        indi = pd.DatetimeIndex(created_at)\n",
        "\n",
        "        discretizations = list(indi.weekday)\n",
        "        self.indexes, self.data_idx, self.idx_data = buildIndexData(discretizations, start_index)\n",
        "        return self.indexes, self.data_idx, self.idx_data\n",
        "\n",
        "    def transform(self, created_at):\n",
        "        indi = pd.DatetimeIndex(created_at)\n",
        "        discretizations = list(indi.weekday)\n",
        "        indexes = [self.data_idx.get(data,None) for data in discretizations]\n",
        "        return indexes\n",
        "\n",
        "\n",
        "class HourofDay_DayofWeak(Discretize):\n",
        "    def fit_transform(self, created_at, start_index = 0):\n",
        "        indi = pd.DatetimeIndex(created_at)\n",
        "\n",
        "        discretizations = list(zip(indi.weekday, indi.hour))\n",
        "        self.indexes, self.data_idx, self.idx_data = buildIndexData(discretizations, start_index)\n",
        "        return self.indexes, self.data_idx, self.idx_data\n",
        "\n",
        "    def transform(self, created_at):\n",
        "        indi = pd.DatetimeIndex(created_at)\n",
        "\n",
        "        discretizations = list(zip(indi.weekday, indi.hour))\n",
        "        indexes = [self.data_idx.get(data, None) for data in discretizations]\n",
        "        return indexes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "83kiVYqij4qA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class Indexer():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_transform(self,\n",
        "            filename,\n",
        "            time_discretizer = HourofDay,\n",
        "            coor_discretizer = Round,\n",
        "            #represent_text = RepresentText,\n",
        "            dates_vocab_size = 0, dates_vocab_mincount = 0,\n",
        "            places_vocab_size = 0, places_vocab_mincount = 0,\n",
        "            words_vocab_size = 0, words_vocab_mincount = 0): #file_csv has columns created_at, latitude, longitude, text\n",
        "\n",
        "        #self.datapath = \"Data\" + sep\n",
        "        if (filename.split('.')[1] == 'csv'):\n",
        "            df = pd.read_csv(filename)\n",
        "        elif (filename.split('.')[1] == 'p'):\n",
        "            df = pd.read_pickle(filename)\n",
        "\n",
        "        self.time_discretizer = time_discretizer()\n",
        "        self.coor_discretizer = coor_discretizer(100)\n",
        "        #self.represent_text = represent_text()\n",
        "\n",
        "\n",
        "\n",
        "        #date_out, self.date_idx, self.idx_date = self.time_discretizer.fit_transform(df['created_at'], start_index = 0)\n",
        "        dates = self.time_discretizer.transform(df['created_at'])\n",
        "\n",
        "        #self.coor_out, self.coor_idx, self.idx_coor = self.coor_discretizer.fit_transform(df['latitude'], df['longitude'],start_index=max(self.date_out) + 1)\n",
        "\n",
        "        places = self.coor_discretizer.transform(df['latitude'], df['longitude'])\n",
        "\n",
        "        '''\n",
        "        datapath = \"SavedModels\" + sep\n",
        "        modelpath = datapath+\"represent_text_\"+ filename.split('.')[0]  +\"words\"+str(words_min_count)+\".model\"\n",
        "        if os.path.isfile(modelpath):\n",
        "            self.represent_text = pickle.load(open(datapath+\"represent_text_\"+ filename.split('.')[0]+ \".model\", \"rb\"))\n",
        "\n",
        "            self.texts_out = pickle.load(open(datapath+\"texts_out\"+ filename.split('.')[0]  +\".p\", \"rb\"))\n",
        "            self.keyword_idx = pickle.load(open(datapath+\"keyword_idx_\"+ filename.split('.')[0]  +\".p\", \"rb\"))\n",
        "            self.idx_keyword = pickle.load(open(datapath+\"idx_keyword_\"+ filename.split('.')[0]  +\".p\", \"rb\"))\n",
        "\n",
        "\n",
        "        else:\n",
        "            self.texts_out, self.keyword_idx, self.idx_keyword = self.represent_text.fit_transform(df['texts'], start_index= max(self.coor_out) + 1, vocab_min_count= words_min_count)\n",
        "\n",
        "            pickle.dump( self.represent_text, open(modelpath, \"wb\" ), pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "            pickle.dump( self.texts_out, open(datapath+\"texts_out\"+ filename.split('.')[0]+ \".p\", \"wb\" ))\n",
        "            pickle.dump( self.keyword_idx, open(datapath+\"keyword_idx_\"+ filename.split('.')[0]+ \".p\", \"wb\" ) )\n",
        "            pickle.dump( self.idx_keyword, open(datapath+\"idx_keyword_\"+ filename.split('.')[0]+ \".p\", \"wb\" ) )\n",
        "\n",
        "        '''\n",
        "        texts = df['texts'].astype(str)\n",
        "        words = [word for list_words in texts for word in list_words.split()]\n",
        "        #print(len(texts))\n",
        "\n",
        "\n",
        "        counter_dates = Counter(dates)\n",
        "        if (dates_vocab_size > 0):\n",
        "            pairs = counter_dates.most_common(dates_vocab_size)\n",
        "        else:\n",
        "            pairs = list(counter_dates.items())\n",
        "        self.vocab_dates = set([date for date, count in pairs if count >= dates_vocab_mincount])\n",
        "\n",
        "\n",
        "        counter_places = Counter(places)\n",
        "        if (places_vocab_size > 0):\n",
        "            pairs = counter_places.most_common(places_vocab_size)\n",
        "        else:\n",
        "            pairs = list(counter_places.items())\n",
        "        self.vocab_places = set([place for place, count in pairs if count >= places_vocab_mincount])\n",
        "\n",
        "\n",
        "        counter_words = Counter(words)\n",
        "        if (words_vocab_size > 0):\n",
        "            pairs = counter_words.most_common(words_vocab_size)\n",
        "        else:\n",
        "            pairs = list(counter_words.items())\n",
        "\n",
        "        self.vocab_words = set([keyword for keyword, count in pairs if count >= words_vocab_mincount])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        filtered_dates = set([i for i in range(len(dates)) if dates[i] in self.vocab_dates ])\n",
        "        filtered_places = set([i for i in range(len(places)) if places[i] in self.vocab_places])\n",
        "        filtered_words = set([i for i in range(len(texts)) if any([word in self.vocab_words for word in texts[i].split()]) ])\n",
        "\n",
        "        #print(len(filtered_dates))\n",
        "        #print(len(filtered_places))\n",
        "        #print(len(filtered_words))\n",
        "\n",
        "\n",
        "\n",
        "        filtered = list(filtered_dates.intersection(filtered_places).intersection(filtered_words))\n",
        "        #print(len(filtered))\n",
        "\n",
        "        dates = [dates[i] for i in filtered]\n",
        "        places = [places[i] for i in filtered]\n",
        "        texts = [texts[i] for i in filtered]\n",
        "\n",
        "\n",
        "        idxsdates, self.date2idx, self.idx2date = buildIndexData(dates, start_index=0)\n",
        "        idxsplaces, self.place2idx, self.idx2place = buildIndexData(places, start_index=max(idxsdates) + 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        idxs, self.word2idx, self.idx2word = buildIndexData(self.vocab_words, start_index = max(idxsplaces) + 1)\n",
        "\n",
        "\n",
        "        idxstexts = []\n",
        "\n",
        "        for text in texts:\n",
        "            indexed_text = [self.word2idx[word] for word in text.split() if word in self.vocab_words]\n",
        "            idxstexts.append(indexed_text)\n",
        "\n",
        "\n",
        "        self.idx2item = {}\n",
        "        self.idx2item.update(self.idx2word)\n",
        "        self.idx2item.update(self.idx2place)\n",
        "        self.idx2item.update(self.idx2date)\n",
        "\n",
        "        self.item2idx = {}\n",
        "        self.item2idx.update(self.word2idx)\n",
        "        self.item2idx.update(self.place2idx)\n",
        "        self.item2idx.update(self.date2idx)\n",
        "\n",
        "        return list(zip(idxsdates,\n",
        "                             idxsplaces,\n",
        "                             idxstexts))\n",
        "\n",
        "\n",
        "    def transform(self, filename):\n",
        "        if (filename.split('.')[1] == 'csv'):\n",
        "            df = pd.read_csv( filename)\n",
        "        elif (filename.split('.')[1] == 'p'):\n",
        "            df = pd.read_pickle( filename)\n",
        "\n",
        "        dates = self.time_discretizer.transform(df['created_at'])\n",
        "        idxsdates = [self.date2idx.get(date, None) for date in dates]\n",
        "\n",
        "        places = self.coor_discretizer.transform(df['latitude'], df['longitude'])\n",
        "        idxsplaces = [self.place2idx.get(place, None) for place in places]\n",
        "\n",
        "        idxstexts = []\n",
        "        for text in df['texts'].astype(str):\n",
        "            indexed_text = [self.word2idx[word] for word in text.split() if word in self.vocab_words]\n",
        "            idxstexts.append(indexed_text)\n",
        "\n",
        "\n",
        "        full_list = list(zip(idxsdates,\n",
        "                             idxsplaces,\n",
        "                             idxstexts))\n",
        "        #print(len(full_list))\n",
        "        clean_list = [(x[0], x[1], x[2]) for x in full_list if ((x[0] != None) and (x[1] != None) and (x[2] != [])) ]\n",
        "        return clean_list\n",
        "\n",
        "\n",
        "    def Item2index(self, item):\n",
        "        return self.item2idx.get(item, -1)\n",
        "\n",
        "    def Index2item(self, index):\n",
        "        return self.idx2item.get(index, None)\n",
        "\n",
        "    def indexes(self):\n",
        "        return (self.coor_out[0], self.coor_out[-1], self.texts_out[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Nr0OFbBnUOj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ec7c93bc-ef07-4a54-867c-46072343da02"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "indexerST = Indexer()\n",
        "trainST = indexerST.fit_transform(data+'tweets2016_2half.csv', dates_vocab_mincount=0, words_vocab_mincount=100, places_vocab_mincount=10)\n",
        "testST = indexerST.transform(data+'toy_2017_Jan.csv')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11 s, sys: 248 ms, total: 11.3 s\n",
            "Wall time: 11.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wO76vzQhnUSR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cb74e43f-8881-4521-d886-c7b7b10110ee"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "indexerLA = Indexer()\n",
        "trainLA = indexerLA.fit_transform(data+'tweetsLAtrain.csv', dates_vocab_mincount=0, words_vocab_mincount=100, places_vocab_mincount=10)\n",
        "testLA = indexerLA.transform(data+'tweetsLAtest.csv')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 40.4 s, sys: 797 ms, total: 41.2 s\n",
            "Wall time: 41.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ehoAepDonUWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "49baa354-7071-4c7b-c5ce-3b1b8ecd68b2"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "indexerNY = Indexer()\n",
        "trainNY = indexerNY.fit_transform(data+'tweetsNYtrain.csv', dates_vocab_mincount=0, words_vocab_mincount=100, places_vocab_mincount=10)\n",
        "testNY = indexerNY.transform(data+'tweetsNYtest.csv')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11.4 s, sys: 101 ms, total: 11.5 s\n",
            "Wall time: 11.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BzJ5V6vZsve1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class QuantitativeEvaluator:\n",
        "    def __init__(self, fake_num=10):\n",
        "        self.ranks = []\n",
        "\n",
        "        self.fake_num = fake_num\n",
        "\n",
        "\n",
        "    def get_ranks(self, test, predictor, predict_type = 'w'):\n",
        "        self.predict_type = predict_type\n",
        "        noiseList = np.random.choice(len(test), self.fake_num*len(test)).tolist()\n",
        "        count = 5\n",
        "        for example in test:\n",
        "\n",
        "\n",
        "\n",
        "            scores = []\n",
        "            score = predictor.predict(example[0], example[1], example[2])\n",
        "            scores.append(score)\n",
        "\n",
        "\n",
        "            for i in range(self.fake_num):\n",
        "                noise = test[noiseList.pop()]\n",
        "                if self.predict_type == 't':\n",
        "                    noise_score = predictor.predict(noise[0], example[1], example[2])\n",
        "                elif self.predict_type=='l':\n",
        "                    noise_score = predictor.predict(example[0], noise[1], example[2])\n",
        "                elif self.predict_type=='w':\n",
        "                    noise_score = predictor.predict(example[0], example[1], noise[2])\n",
        "                scores.append(noise_score)\n",
        "            scores.sort()\n",
        "\n",
        "\n",
        "            # handle ties\n",
        "            rank = len(scores)+1-(bisect.bisect_left(scores,score)+bisect.bisect_right(scores,score)+1)/2.0\n",
        "            self.ranks.append(rank)\n",
        "\n",
        "\n",
        "    def get_ranks_old(self, np_xytest, predictor, predict_type = 'w'):\n",
        "        self.predict_type = predict_type\n",
        "        noiseList = np.random.choice(np_xytest.shape[0], self.fake_num*np_xytest.shape[0]).tolist()\n",
        "\n",
        "        for i in range(np_xytest.shape[0]):\n",
        "            example = list(np_xytest[i])\n",
        "            scores = []\n",
        "            score = predictor.predict(example[0], example[1], example[2])\n",
        "            scores.append(score)\n",
        "\n",
        "            for i in range(self.fake_num):\n",
        "                noise = np_xytest[noiseList.pop()]\n",
        "                if self.predict_type == 'l':\n",
        "                    noise_score = predictor.predict(noise[0], example[1], example[2])\n",
        "                elif self.predict_type=='t':\n",
        "                    noise_score = predictor.predict(example[0], noise[1], example[2])\n",
        "                elif self.predict_type=='w':\n",
        "                    noise_score = predictor.predict(example[0], example[1], noise[2])\n",
        "                scores.append(noise_score)\n",
        "            scores.sort()\n",
        "            # handle ties\n",
        "            rank = len(scores)+1-(bisect.bisect_left(scores,score)+bisect.bisect_right(scores,score)+1)/2.0\n",
        "            self.ranks.append(rank)\n",
        "\n",
        "    def compute_mrr(self):\n",
        "        r = self.ranks\n",
        "        reciprocal_ranks = [1/rank for rank in r]\n",
        "        mrr = sum(reciprocal_ranks)/len(reciprocal_ranks)\n",
        "        mr = sum(r)/len(r)\n",
        "        return round(mrr,4), round(mr,4)\n",
        "\n",
        "\n",
        "class QualitativeEvaluator:\n",
        "    def __init__(self, predictor, output_dir):\n",
        "        self.predictor = predictor\n",
        "        self.output_dir = output_dir\n",
        "\n",
        "    def plot_locations_on_google_map(self, locations, output_path):\n",
        "        request ='https://maps.googleapis.com/maps/api/staticmap?zoom=10&size=600x600&maptype=roadmap&'\n",
        "        for lat, lng in locations:\n",
        "            request += 'markers=color:red%7C' + '%f,%f&' % (lat, lng)\n",
        "        proxy = urllib.ProxyHandler({})\n",
        "        opener = urllib.build_opener(proxy)\n",
        "        response = opener.open(request).read()\n",
        "        with open(output_path, 'wb') as f:\n",
        "            f.write(response)\n",
        "            f.close()\n",
        "        time.sleep(3)\n",
        "\n",
        "    def scribe(self, directory, ls, ts, ws, show_ls):\n",
        "        if not os.path.isdir(directory):\n",
        "            os.makedirs(directory)\n",
        "        for nbs, file_name in [(ts, 'times.txt'), (ws, 'words.txt')]:\n",
        "            output_file = open(directory+file_name,'w')\n",
        "            for nb in nbs:\n",
        "                output_file.write(str(nb)+'\\n')\n",
        "        if show_ls:\n",
        "            self.plot_locations_on_google_map(ls[:10], directory+'locations.png')\n",
        "        else:\n",
        "            self.plot_locations_on_google_map(ls[:1], directory+'queried_location.png')\n",
        "\n",
        "    def getNbs1(self, query):\n",
        "        if type(query)==str and query.lower() not in self.predictor.nt2vecs['w']:\n",
        "            print (query, 'not in voca')\n",
        "            return\n",
        "        directory = self.output_dir+str(query)+'/'\n",
        "        ls, ts, ws = [self.predictor.get_nbs1(query, nt) for nt in ['l', 't', 'w']]\n",
        "        self.scribe(directory, ls, ts, ws, type(query)!=list)\n",
        "\n",
        "    def getNbs2(self, query1, query2, func=lambda a, b:a+b):\n",
        "        if type(query1)==str and query1.lower() not in self.predictor.nt2vecs['w']:\n",
        "            print (query1, 'not in voca')\n",
        "            return\n",
        "        if type(query2)==str and query2.lower() not in self.predictor.nt2vecs['w']:\n",
        "            print (query2, 'not in voca')\n",
        "            return\n",
        "        directory = self.output_dir+str(query1)+'-'+str(query2)+'/'\n",
        "        ls, ts, ws = [self.predictor.get_nbs2(query1, query2, func, nt) for nt in ['l', 't', 'w']]\n",
        "        self.scribe(directory, ls, ts, ws, type(query1)!=list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bbiGFbPwveHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bd68543a-7bd0-4ca0-da31-38ad2e372590"
      },
      "cell_type": "code",
      "source": [
        "t = torch.zeros([150,2,100])\n",
        "print(t.shape)\n",
        "print(torch.sum(t, dim=1).shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fKDUM7jvCQJb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Models"
      ]
    },
    {
      "metadata": {
        "id": "AJH1LJyznUgU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class EmbedModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, range_times, range_coors, range_words):\n",
        "        super(EmbedModel, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linearTimes = nn.Linear(2 * embedding_dim, max(range_times)-min(range_times)+1, bias=False)\n",
        "        self.linearCoors = nn.Linear(2 * embedding_dim, max(range_coors)-min(range_coors)+1, bias=False)\n",
        "        self.linearWords = nn.Linear(2 * embedding_dim, max(range_words)-min(range_words)+1, bias=False)\n",
        "        self.range_times = range_times\n",
        "        self.range_coors = range_coors\n",
        "        self.range_words = range_words\n",
        "        \n",
        "    def forward(self, inputs, target):\n",
        "      \n",
        "      \n",
        "        embeds = self.embeddings(inputs).view((1, -1))\n",
        "        \n",
        "        \n",
        "        if target in self.range_times:\n",
        "           out = F.relu(self.linearTimes(embeds))\n",
        "\n",
        "\n",
        "        elif target in self.range_coors:\n",
        "            out = F.relu(self.linearCoors(embeds))\n",
        "                      \n",
        "                        \n",
        "\n",
        "        else:#target in range_words\n",
        "            out = F.relu(self.linearWords(embeds))\n",
        "        \n",
        "        log_probs = F.log_softmax(out, dim=1)\n",
        "\n",
        "        return log_probs\n",
        "\n",
        "\n",
        "class EmbedModelBatch(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, range_times, range_coors, range_words, batch_size):\n",
        "        super(EmbedModelBatch, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linearTimes = nn.Linear(embedding_dim, max(range_times)-min(range_times)+1, bias=False)\n",
        "        self.linearCoors = nn.Linear(embedding_dim, max(range_coors)-min(range_coors)+1, bias=False)\n",
        "        self.linearWords = nn.Linear(embedding_dim, max(range_words)-min(range_words)+1, bias=False)\n",
        "        self.range_times = range_times\n",
        "        self.range_coors = range_coors\n",
        "        self.range_words = range_words\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "    def forward(self, inputs, target):\n",
        "      \n",
        "        #print(target)\n",
        "        embeds = self.embeddings(inputs)\n",
        "        print(embeds.shape)\n",
        "        print(torch.sum(embeds[:], dim=0).shape)\n",
        "        \n",
        "        \n",
        "        embeds = embeds.view((self.batch_size,-1))\n",
        "        \n",
        "        \n",
        "        if target == 0:\n",
        "           out = F.relu(self.linearTimes(embeds))\n",
        "\n",
        "\n",
        "        elif target == 1:\n",
        "            out = F.relu(self.linearCoors(embeds))\n",
        "                      \n",
        "                        \n",
        "\n",
        "        else:#target in range_words\n",
        "            out = F.relu(self.linearWords(embeds))\n",
        "        \n",
        "        log_probs = F.log_softmax(out, dim=1)\n",
        "\n",
        "        return log_probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class SimpleEmbedding():\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "    def transform_as_nparray(self, tuples_train):\n",
        "\n",
        "        output = []\n",
        "        for (aux_date_idx, aux_coor_idx, text) in tuples_train:\n",
        "            for word_numb in text:\n",
        "                _tuple = (aux_date_idx, aux_coor_idx, word_numb)\n",
        "                output.append(_tuple)\n",
        "        return np.array(output)\n",
        "\n",
        "\n",
        "    def get_input_layer(self, data, vocabulary_size):\n",
        "        x = torch.zeros(vocabulary_size).float()\n",
        "        for i in data:\n",
        "            x[i] = 1.0\n",
        "        return x\n",
        "\n",
        "    def fit(self, tuples_train, embedding_dims, num_epochs = 11):\n",
        "\n",
        "        xytrain = self.transform_as_nparray(tuples_train)\n",
        "        vocabulary_size = int(max(list(xytrain[:, -1]))) + 1\n",
        "\n",
        "        range_times = range(int(max(list(xytrain[:, -3]))) + 1)\n",
        "        range_coor = range(int(max(list(xytrain[:, -3]))) + 1, int(max(list(xytrain[:, -2]))) + 1)\n",
        "        range_words = range(int(max(list(xytrain[:, -2]))) + 1, vocabulary_size)\n",
        "\n",
        "        W1 = Variable(torch.randn(embedding_dims, vocabulary_size).float(), requires_grad=True)\n",
        "        W2 = Variable(torch.randn(vocabulary_size, embedding_dims).float(), requires_grad=True)\n",
        "        learning_rate = 0.001\n",
        "        numexamples = xytrain.shape[0]\n",
        "        print('test')\n",
        "        print(numexamples)\n",
        "        numexamples = 1000\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        for epo in range(num_epochs):\n",
        "            loss_val = 0\n",
        "            for tuple in xytrain[:numexamples]:\n",
        "                # print(tuple)\n",
        "                for i in range(3):\n",
        "                    target = tuple[i]\n",
        "                    data = [tuple[j] for j in range(3) if j != i]\n",
        "\n",
        "\n",
        "\n",
        "                    #x = Variable(self.get_input_layer(data, vocabulary_size)).type(_type)\n",
        "\n",
        "                    #z1 = torch.matmul(W1, x)\n",
        "                    #z1 = W1[:, Variable(torch.from_numpy(np.array(data)).long()).type(_type)]\n",
        "                    #z1 = W1[:, np.array(data)]\n",
        "                    \n",
        "                    if target in range_times:\n",
        "                        y_true = Variable(torch.from_numpy(np.array([target])).long()).type(_typelong)\n",
        "                        z2 = torch.matmul(W2[range_times], W1[:, np.array(data)])\n",
        "                        # print(max_date_idx+1)\n",
        "\n",
        "                    elif target in range_coor:\n",
        "                        y_true = Variable(torch.from_numpy(np.array([target - min(range_coor)])).long()).type(_typelong)\n",
        "                        z2 = torch.matmul(W2[range_coor], W1[:, np.array(data)])\n",
        "                        # print(max_coor_idx+1)\n",
        "\n",
        "                    else:#target in range_words\n",
        "                        y_true = Variable(torch.from_numpy(np.array([target - min(range_words)])).long()).type(_typelong)\n",
        "\n",
        "                        z2 = torch.matmul(W2[range_words], W1[:, np.array(data)])\n",
        "                        # print(vocabulary_size-(max_coor_idx+1+max_date_idx+1))\n",
        "\n",
        "                    # print(y_true)\n",
        "                    # print(z2.shape)\n",
        "\n",
        "                    log_softmax = F.log_softmax(z2, dim=0)\n",
        "\n",
        "                    loss = F.nll_loss(log_softmax.view(1, -1), y_true)\n",
        "                    loss_val += loss.data[0]\n",
        "                    loss.backward()\n",
        "                    #optimizer.step()\n",
        "\n",
        "\n",
        "                    W1.data -= learning_rate * W1.grad.data\n",
        "                    W2.data -= learning_rate * W2.grad.data\n",
        "\n",
        "                    W1.grad.data.zero_()\n",
        "                    W2.grad.data.zero_()\n",
        "\n",
        "        #    if epo % 10 == 0:\n",
        "            print(f'Loss {loss_val/numexamples}')\n",
        "        self.W = torch.cat([W1.transpose(0, 1), W2], 1).detach().data.numpy()\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    def next_batch(self):\n",
        "              \n",
        "        numexamples = self.xytrain.shape[0]\n",
        "        \n",
        "        positions = random.sample(range(numexamples),self.batch_size)\n",
        "        \n",
        "        target = random.sample(range(3),1)\n",
        "        inputs = [j for j in range(3) if j != target[0]]\n",
        "        \n",
        "        \n",
        "        x = self.xytrain[positions][:,inputs]\n",
        "        y = self.xytrain[positions][:,target[0]]\n",
        "        #print(y)\n",
        "        y = y-self.min_ranges[target[0]]\n",
        "        #print(-self.min_ranges[target[0]])\n",
        "        #print(y)\n",
        "        return x, y, target[0]\n",
        "    \n",
        "    def fit_embed_batch(self, tuples_train, embedding_dims, num_epochs = 11, batch_size = 100):\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.xytrain = self.transform_as_nparray(tuples_train)\n",
        "        \n",
        "        vocabulary_size = int(max(list(self.xytrain[:, -1]))) + 1\n",
        "\n",
        "        range_times = range(int(max(list(self.xytrain[:, -3]))) + 1)\n",
        "        range_coors = range(int(max(list(self.xytrain[:, -3]))) + 1, int(max(list(self.xytrain[:, -2]))) + 1)\n",
        "        range_words = range(int(max(list(self.xytrain[:, -2]))) + 1, vocabulary_size)\n",
        "        \n",
        "        self.min_ranges = [min(range_times), min(range_coors), min(range_words)]\n",
        "       \n",
        "        numexamples = self.xytrain.shape[0]\n",
        "        print(numexamples)\n",
        "        #numexamples = 500000\n",
        "        \n",
        "        \n",
        "        \n",
        "        losses = []\n",
        "        #loss_function = nn.NLLLoss()\n",
        "        loss_function = torch.nn.CrossEntropyLoss()\n",
        "        model = EmbedModelBatch(vocabulary_size, embedding_dims, range_times, range_coors, range_words, self.batch_size).to(device)\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            total_loss = 0\n",
        "            \n",
        "            \n",
        "            for _ in range(3*numexamples//self.batch_size):\n",
        "                x, y, target = self.next_batch()\n",
        "                \n",
        "                x = torch.tensor(x, dtype=torch.long)\n",
        "                y = torch.tensor(y, dtype=torch.long)\n",
        "                model.zero_grad()\n",
        "\n",
        "                log_probs = model(x.to(device), target)\n",
        "\n",
        "                                \n",
        "                    \n",
        "                y = torch.tensor(y, dtype=torch.long)\n",
        "                #print(log_probs)\n",
        "                #print(y)\n",
        "                    \n",
        "                #print(log_probs.shape)\n",
        "                #print(y.shape)\n",
        "                loss = loss_function(log_probs, y.to(device))\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "            losses.append(total_loss/numexamples)\n",
        "            \n",
        "            print(total_loss/numexamples)  # The loss decreased every iteration over the training data!\n",
        "        self.W = model.embeddings.weight.data.cpu().numpy()\n",
        "        print(self.W[0])\n",
        "    \n",
        "    \n",
        "    def fit_embed(self, tuples_train, embedding_dims, num_epochs = 11):\n",
        "\n",
        "        xytrain = self.transform_as_nparray(tuples_train)\n",
        "        vocabulary_size = int(max(list(xytrain[:, -1]))) + 1\n",
        "\n",
        "        range_times = range(int(max(list(xytrain[:, -3]))) + 1)\n",
        "        range_coors = range(int(max(list(xytrain[:, -3]))) + 1, int(max(list(xytrain[:, -2]))) + 1)\n",
        "        range_words = range(int(max(list(xytrain[:, -2]))) + 1, vocabulary_size)\n",
        "        self.min_ranges = [min(range_times), min(range_coors), min(range_words)]\n",
        "       \n",
        "        numexamples = xytrain.shape[0]\n",
        "        print(numexamples)\n",
        "        #numexamples = 100\n",
        "        \n",
        "        \n",
        "        \n",
        "        losses = []\n",
        "        loss_function = nn.NLLLoss()\n",
        "        model = EmbedModel(vocabulary_size, embedding_dims, range_times, range_coors, range_words).to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            total_loss = 0\n",
        "            \n",
        "            \n",
        "            for tuple in xytrain[:numexamples]:\n",
        "                # print(tuple)\n",
        "                for i in range(3):\n",
        "                    loss_steps = []\n",
        "                    target = tuple[i]\n",
        "                    # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
        "                    # into integer indices and wrap them in tensors)\n",
        "                    inputs = [tuple[j] for j in range(3) if j != i]\n",
        "                    \n",
        "                    context_idxs = torch.tensor(inputs, dtype=torch.long)\n",
        "                    \n",
        "\n",
        "                    # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
        "                    # new instance, you need to zero out the gradients from the old\n",
        "                    # instance\n",
        "                    model.zero_grad()\n",
        "\n",
        "                    # Step 3. Run the forward pass, getting log probabilities over next\n",
        "                    # words\n",
        "                    log_probs = model(context_idxs.to(device), target)\n",
        "\n",
        "                    # Step 4. Compute your loss function. (Again, Torch wants the target\n",
        "                    # word wrapped in a tensor)\n",
        "                    \n",
        "                    if target in range_times:\n",
        "                        real_index_target = target\n",
        "                        \n",
        "\n",
        "                    elif target in range_coors:\n",
        "                        real_index_target = target - min(range_coors)\n",
        "                        \n",
        "\n",
        "                    else:#target in range_words\n",
        "                        real_index_target = target - min(range_words)\n",
        "\n",
        "                    \n",
        "                    \n",
        "                    y_true = torch.tensor([real_index_target], dtype=torch.long)\n",
        "                    \n",
        "                    \n",
        "                    \n",
        "                    loss = loss_function(log_probs, y_true.to(device))\n",
        "\n",
        "                    # Step 5. Do the backward pass and update the gradient\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
        "                    total_loss += loss.item()\n",
        "            losses.append(total_loss/numexamples)\n",
        "            if epoch % (num_epochs//10) == 0:\n",
        "              print(total_loss/numexamples)  # The loss decreased every iteration over the training data!\n",
        "        self.W = model.embeddings.weight.data.cpu().numpy()\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    def predict(self, t_idx, l_idx, w_idx):\n",
        "        vec_t = self.W[t_idx].reshape(1, -1)\n",
        "        vec_l = self.W[l_idx].reshape(1, -1)\n",
        "\n",
        "        vec_w = np.average([self.W[idx].reshape(1, -1) for idx in w_idx], axis=0)\n",
        "\n",
        "        vectors = [vec_t, vec_l, vec_w]\n",
        "        for vec1, vec2 in itertools.combinations(vectors, r=2):\n",
        "\n",
        "            if (cosine_similarity(vec1, vec2).shape != (1, 1)):\n",
        "                print('cosine_similarity shape error')\n",
        "\n",
        "        score = sum([cosine_similarity(vec1, vec2)[0][0] for vec1, vec2 in itertools.combinations(vectors, r=2)])\n",
        "        return round(score, 6)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UQGAr54gp5LQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20856
        },
        "outputId": "22b34578-15d8-4a38-ea15-7e669b0327d9"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "translate = {'w':'Text','l':'Location','t':'Time'}\n",
        "trainsets = [trainST, trainLA, trainNY]\n",
        "testsets = [testST, testLA, testNY]\n",
        "namesets = ['Santiago','LA','NY']\n",
        "results = {'Model':[],'Dataset':[],  'Text':[], 'Location':[],'Time':[]}\n",
        "for train,test,name in list(zip(trainsets, testsets, namesets))[:1]:\n",
        "    QE = QuantitativeEvaluator()\n",
        "    \n",
        "    dims = [100]\n",
        "    \n",
        "    model = SimpleEmbedding()\n",
        "    \n",
        "    \n",
        "    for dim in dims:\n",
        "        model.fit_embed_batch(train, embedding_dims=dim, num_epochs=100, batch_size = 150)\n",
        "        for predict_type in 'wlt':\n",
        "            QE.get_ranks(test, model, predict_type = predict_type)\n",
        "            mrr1 = QE.compute_mrr()[0]\n",
        "            print(mrr1)\n",
        "            results[translate[predict_type]].append(mrr1)\n",
        "        results['Dataset'].append(name)\n",
        "        results['Model'].append(str(type(model))+'_'+str())\n",
        "        df = pd.DataFrame(results)\n",
        "                \n",
        "        df.to_csv('resultsemb.df')\n",
        "        uploaded = drive.CreateFile()\n",
        "        uploaded.SetContentFile('resultsemb.df')\n",
        "        uploaded.Upload()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1327127\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n",
            "torch.Size([150, 2, 100])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c9b7cbe827fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"translate = {'w':'Text','l':'Location','t':'Time'}\\ntrainsets = [trainST, trainLA, trainNY]\\ntestsets = [testST, testLA, testNY]\\nnamesets = ['Santiago','LA','NY']\\nresults = {'Model':[],'Dataset':[],  'Text':[], 'Location':[],'Time':[]}\\nfor train,test,name in list(zip(trainsets, testsets, namesets))[:1]:\\n    QE = QuantitativeEvaluator()\\n    \\n    dims = [100]\\n    \\n    model = SimpleEmbedding()\\n    \\n    \\n    for dim in dims:\\n        model.fit_embed_batch(train, embedding_dims=dim, num_epochs=100, batch_size = 150)\\n        for predict_type in 'wlt':\\n            QE.get_ranks(test, model, predict_type = predict_type)\\n            mrr1 = QE.compute_mrr()[0]\\n            print(mrr1)\\n            results[translate[predict_type]].append(mrr1)\\n        results['Dataset'].append(name)\\n        results['Model'].append(str(type(model))+'_'+str())\\n        df = pd.DataFrame(results)\\n                \\n        df.to_csv('resultsemb.df')\\n        uploaded = drive.CreateFile()\\n        uploaded.SetContentFile('resultsemb.df')\\n        uploaded.Upload()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-7badb5771aaf>\u001b[0m in \u001b[0;36mfit_embed_batch\u001b[0;34m(self, tuples_train, embedding_dims, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4bWEHTzUnUZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "da850ae4-93eb-41f5-b145-3688fb9bae1b"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "%time\n",
        "for train,test,name in list(zip(trainsets, testsets, namesets))[:1]:\n",
        "    QE = QuantitativeEvaluator()\n",
        "    \n",
        "    dims = [10]\n",
        "    \n",
        "    model = SimpleEmbedding()\n",
        "    \n",
        "    \n",
        "    for dim in dims:\n",
        "        model.fit_embed_batch(train, embedding_dims=dim, num_epochs=2,batch_size=1000)\n",
        "        path = 'model_dim_'+str(dim)+'_'+name\n",
        "        torch.save(model, path)\n",
        "        uploaded = drive.CreateFile()\n",
        "        uploaded.SetContentFile(path)\n",
        "        uploaded.Upload()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
            "Wall time: 9.06 µs\n",
            "1327127\n",
            "tensor([[-0.2848, -0.3738,  0.0541,  0.4920,  0.3677,  0.7600, -1.2157, -0.8996,\n",
            "         -0.8480, -0.1504]], grad_fn=<EmbeddingBackward>)\n",
            "0.018999799914893416\n",
            "0.018842834003921675\n",
            "[-0.28268117 -0.37250555  0.05357122  0.49386552  0.3666874   0.75614697\n",
            " -1.212168   -0.89712894 -0.8461886  -0.14885308]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TdsKrno86Lba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5714389f-584f-4239-fd96-19129a4b3a9e"
      },
      "cell_type": "code",
      "source": [
        "%time\n",
        "for train,test,name in list(zip(trainsets, testsets, namesets))[:1]:\n",
        "    QE = QuantitativeEvaluator()\n",
        "    \n",
        "    dims = [20]\n",
        "    \n",
        "    model = SimpleEmbedding()\n",
        "    \n",
        "    \n",
        "    for dim in dims:\n",
        "        model.fit_embed_batch(train, embedding_dims=dim, num_epochs=10)\n",
        "        path = 'model_dim_'+str(dim)+'_'+name\n",
        "        torch.save(model, path)\n",
        "        uploaded = drive.CreateFile()\n",
        "        uploaded.SetContentFile(path)\n",
        "        uploaded.Upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
            "Wall time: 9.3 µs\n",
            "1327127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WtaqttuhqM0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "outputId": "bd29734a-7875-49fc-eea9-00d32f62b6ef"
      },
      "cell_type": "code",
      "source": [
        "results = {'Model':[],'Dataset':[],  'Text':[], 'Location':[],'Time':[]}\n",
        "for train,test,name in list(zip(trainsets, testsets, namesets)):\n",
        "    QE = QuantitativeEvaluator()\n",
        "    \n",
        "    dims = [20,60,100,160,200]\n",
        "    \n",
        "    model = SimpleEmbedding()\n",
        "    \n",
        "    \n",
        "    for dim in dims:\n",
        "        model.fit_embed(train, embedding_dims=dim, num_epochs=3)\n",
        "    \n",
        "    \n",
        "        for predict_type in 'wlt':\n",
        "            QE.get_ranks(test, model, predict_type = predict_type)\n",
        "            mrr1 = QE.compute_mrr()[0]\n",
        "            print(mrr1)\n",
        "            results[translate[predict_type]].append(mrr1)\n",
        "        results['Dataset'].append(name)\n",
        "        results['Model'].append(str(type(model))+'_'+str())\n",
        "        df = pd.DataFrame(results)\n",
        "                \n",
        "        df.to_csv('resultsemb.df')\n",
        "        uploaded = drive.CreateFile()\n",
        "        uploaded.SetContentFile('resultsemb.df')\n",
        "        uploaded.Upload()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1327127\n",
            "17.30460192312956\n",
            "16.043830757434367\n",
            "15.524767640408278\n",
            "0.2691\n",
            "0.2695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b9b45def1a1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpredict_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'wlt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mQE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ranks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mmrr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mrr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmrr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-0348e733cd37>\u001b[0m in \u001b[0;36mget_ranks\u001b[0;34m(self, test, predictor, predict_type)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoiseList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m't'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0mnoise_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'l'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mnoise_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-7d4d19372054>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, t_idx, l_idx, w_idx)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cosine_similarity shape error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_normalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1436\u001b[0m             \u001b[0mnorms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0mnorms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_handle_zeros_in_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JfyrcmqttFvL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}