{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Represent_As_Doc.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/juglar-diaz/STTD/blob/master/Represent_As_Doc.ipynb","timestamp":1540839224360}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"c02j_-p6TZ2r","colab_type":"text"},"cell_type":"markdown","source":["#Intro"]},{"metadata":{"id":"R3QjBnH6lktK","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install -U -q PyDrive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LJWrJduhlnI-","colab_type":"code","colab":{}},"cell_type":"code","source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jGPfqOgRnsBQ","colab_type":"code","outputId":"6fcc2135-d401-48a0-9059-f19e6ad330db","colab":{"base_uri":"https://localhost:8080/","height":757},"executionInfo":{"status":"ok","timestamp":1540836845904,"user_tz":180,"elapsed":11924,"user":{"displayName":"","photoUrl":"","userId":""}}},"cell_type":"code","source":["from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","print(accelerator)\n","!pip3 install gensim\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["cpu\n","Collecting gensim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/a4/d10c0acc8528d838cda5eede0ee9c784caa598dbf40bd0911ff8d067a7eb/gensim-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (23.6MB)\n","\u001b[K    100% |████████████████████████████████| 23.6MB 1.2MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n","Collecting smart-open>=1.2.1 (from gensim)\n","  Downloading https://files.pythonhosted.org/packages/4b/1f/6f27e3682124de63ac97a0a5876da6186de6c19410feab66c1543afab055/smart_open-1.7.1.tar.gz\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n","Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n","\u001b[K    100% |████████████████████████████████| 1.4MB 12.0MB/s \n","\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n","  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n","Collecting boto3 (from smart-open>=1.2.1->gensim)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/3f/fa68bacf76b12e4258240a9bdb6569fb4b041f7586c984be53603e88ca35/boto3-1.9.33-py2.py3-none-any.whl (128kB)\n","\u001b[K    100% |████████████████████████████████| 133kB 29.4MB/s \n","\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.10.15)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n","Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n","  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n","Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 22.4MB/s \n","\u001b[?25hCollecting botocore<1.13.0,>=1.12.33 (from boto3->smart-open>=1.2.1->gensim)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/36/f9c082bb4d20db5b271920db657589ee3d6784d5f40c30b3c8600b80d4a5/botocore-1.12.33-py2.py3-none-any.whl (4.7MB)\n","\u001b[K    100% |████████████████████████████████| 4.7MB 6.9MB/s \n","\u001b[?25hCollecting docutils>=0.10 (from botocore<1.13.0,>=1.12.33->boto3->smart-open>=1.2.1->gensim)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n","\u001b[K    100% |████████████████████████████████| 552kB 26.0MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.33->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n","Building wheels for collected packages: smart-open, bz2file\n","  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/23/00/44/e5b939f7a80c04e32297dbd6d96fa3065af89ecf57e2b5f89f\n","  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n","Successfully built smart-open bz2file\n","Installing collected packages: boto, bz2file, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n","Successfully installed boto-2.49.0 boto3-1.9.33 botocore-1.12.33 bz2file-0.98 docutils-0.14 gensim-3.6.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.7.1\n"],"name":"stdout"}]},{"metadata":{"id":"lboU3CzKkHsc","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n","import itertools\n","from gensim import models\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.decomposition import NMF, LatentDirichletAllocation\n","from scipy.sparse import csr_matrix\n","\n","import random\n","\n","\n","\n","import pickle\n","\n","import os\n","sep = os.sep\n","import os.path\n","\n","import pandas as pd\n","\n","import time\n","\n","\n","if(os.path.isfile('utils.py')):\n","    !rm 'utils.py'\n","    print(\"deleted\")\n","\n","exchangedrive = drive.CreateFile({'id':'12djgLg96tD7ynEhImcqoYnL5ZamenDEM'})\n","exchangedrive.GetContentFile('utils.py')\n","\n","from utils import *\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s6m5UOXClc5v","colab_type":"text"},"cell_type":"markdown","source":["#Download Data"]},{"metadata":{"id":"Nrks3-MplPnI","colab_type":"code","colab":{}},"cell_type":"code","source":["exchangedrive = drive.CreateFile({'id':'1cMCzlvTMlUPgaYaUIdlMVtTpp8r10GnX'})\n","exchangedrive.GetContentFile('robosclean.p')\n","\n","\n","exchangedrive = drive.CreateFile({'id':'1A5Wa6LiaGs8XeW2S2qjGbcoSSlsMGW97'})\n","exchangedrive.GetContentFile('tweetsLAtrain.csv')\n","exchangedrive = drive.CreateFile({'id':'1CrUCS7oWzdvYoFwtWgikiGkDAu6w3dOF'})\n","exchangedrive.GetContentFile('tweetsLAtest.csv')\n","exchangedrive = drive.CreateFile({'id':'1AU_saqdyRxtgMX2TC7Q42OBIUm68cdw_'})\n","exchangedrive.GetContentFile('tweetsLA.csv')\n","\n","\n","\n","exchangedrive = drive.CreateFile({'id':'1NuSVM7-h0CCRtzi0woM4h5tVd6T7JO2C'})\n","exchangedrive.GetContentFile('tweetsNYtrain.csv')\n","exchangedrive = drive.CreateFile({'id':'1UYZY0sh1-Q8MIofMAHDGaNKv8cfDA0ui'})\n","exchangedrive.GetContentFile('tweetsNYtest.csv')\n","\n","\n","exchangedrive = drive.CreateFile({'id':'1Jv19eJTZwsZWEA_rUudvKwcn1TS-DFBa'})\n","exchangedrive.GetContentFile('tweets2016_2half.csv')\n","exchangedrive = drive.CreateFile({'id':'1E8WlhOXb3tfQbLUpizx7QXzeydv57eXN'})\n","exchangedrive.GetContentFile('toy_2017_Jan.csv')\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fKDUM7jvCQJb","colab_type":"text"},"cell_type":"markdown","source":["#Models"]},{"metadata":{"id":"7S5_mCHKVqul","colab_type":"code","colab":{}},"cell_type":"code","source":["class RepreAsDoc():\n","    def __init__(self):\n","        pass\n","\n","\n","    def fit(self, tuples_train, tf_idf = False, lda = False):#t is a tuple (date_out, coor_out, tweets_out)\n","\n","        ldates_as_doc = []# a list of [wordidx,...,wordidx]), where the index of the list is a dateidx or a cooridx or a wordidx\n","        lcoor_as_doc = []# a list of [wordidx,...,wordidx]), where the index of the list is a cooridx\n","\n","        self.max_idxdate = max([tuple[0] for tuple in tuples_train])\n","        #print(self.max_idxdate)\n","        self.min_idxword = max([tuple[1] for tuple in tuples_train]) + 1\n","        #print(self.min_idxword)\n","\n","\n","        max_idxword = 0\n","        for tuple in tuples_train:\n","            for idxword in tuple[2]:\n","                if idxword > max_idxword:\n","                    max_idxword = idxword\n","        #print(max_idxword)\n","        self.max_idxword = max_idxword\n","\n","\n","        min_idxword = max_idxword\n","        for tuple in tuples_train:\n","            for idxword in tuple[2]:\n","                if idxword < min_idxword:\n","                    min_idxword = idxword\n","        #print(min_idxword)\n","\n","        vectors = [[] for _ in range(max_idxword+1)]\n","\n","        for i in range(max_idxword+1):\n","            vectors[i] = [0 for _ in range(max_idxword-min_idxword + 1)]\n","\n","        for tuple in tuples_train:\n","            dateidx, cooridx, wordsidxs = tuple[0], tuple[1], tuple[2]\n","            for idxword in wordsidxs:\n","                vectors[dateidx][idxword-min_idxword] += 1\n","                vectors[cooridx][idxword-min_idxword] += 1\n","\n","                for word_idx in wordsidxs:\n","                    vectors[word_idx][idxword-min_idxword] += 1\n","\n","        if(tf_idf and not lda):\n","            tfidf_model = TfidfTransformer()\n","            vectors = tfidf_model.fit_transform(vectors)\n","            vectors = vectors.todense()\n","\n","        if(tf_idf and lda):\n","            tfidf_model = TfidfTransformer()\n","            vectors = tfidf_model.fit_transform(vectors)\n","\n","            lda_model = LatentDirichletAllocation(n_components=20, max_iter=5,\n","                                            learning_method='online',\n","                                            learning_offset=50.,\n","                                            random_state=0)\n","            vectors = lda_model.fit_transform(vectors)\n","\n","        if (not tf_idf and lda):\n","\n","            vectors = csr_matrix(vectors)\n","\n","            lda_model = LatentDirichletAllocation(n_components=20, max_iter=5,\n","                                                  learning_method='online',\n","                                                  learning_offset=50.,\n","                                                  random_state=0)\n","            vectors = lda_model.fit_transform(vectors)\n","\n","        self.W = np.array(vectors)\n","\n","    def predict(self, t_idx, l_idx, w_idx):\n","        vec_t = self.W[t_idx].reshape(1, -1)\n","        vec_l = self.W[l_idx].reshape(1, -1)\n","\n","        vec_w = np.average([self.W[idx].reshape(1, -1) for idx in w_idx], axis=0)\n","\n","        vectors = [vec_t, vec_l, vec_w]\n","        #print(vec_t.shape, vec_l.shape, vec_w.shape)\n","        #for vec1, vec2 in itertools.combinations(vectors, r=2):\n","        #    if (cosine_similarity(vec1, vec2).shape != (1, 1)):\n","        #        print('cosine_similarity shape error')\n","        #    print(cosine_similarity(vec1, vec2))\n","        score = sum([cosine_similarity(vec1, vec2)[0][0] for vec1, vec2 in itertools.combinations(vectors, r=2)])\n","        return round(score, 6)\n","\n","    def getPlaces(self):\n","        return self.W[self.max_idxdate+1:self.min_idxword,:]\n","\n","    def queryItem(self, idxs, number= 10):\n","        query_vectors = self.W[idxs]\n","        query_vectors.reshape(query_vectors.shape[0],1,-1)\n","        #print(self.max_idxdate+1)\n","\n","        date_vectors = self.W[list(range(0,self.max_idxdate+1))]\n","        #print(date_vectors)\n","\n","        date_vectors.reshape(date_vectors.shape[0], 1, -1)\n","\n","        cosines_sim_date = cosine_similarity(query_vectors, date_vectors)\n","\n","\n","\n","        #coor_vectors = self.W[list(range(self.max_idxdate+1,self.min_idxword))]\n","        coor_vectors = self.W[self.max_idxdate+1:self.min_idxword,:]\n","        #print(coor_vectors)\n","\n","        coor_vectors.reshape(coor_vectors.shape[0], 1, -1)\n","        cosines_sim_coor = cosine_similarity(query_vectors, coor_vectors)\n","\n","        word_vectors = self.W[list(range(self.min_idxword, self.max_idxword + 1))]\n","        word_vectors.reshape(word_vectors.shape[0], 1, -1)\n","        cosines_sim_word = cosine_similarity(query_vectors, word_vectors)\n","\n","\n","        indexes_date = np.argsort(cosines_sim_date, )\n","        indexes_coor = np.argsort(cosines_sim_coor) + self.max_idxdate+1\n","        indexes_word = np.argsort(cosines_sim_word) + self.min_idxword\n","\n","        return (indexes_date[:1,-number:], indexes_coor[:1,-number:], indexes_word[:1,-number:])\n","\n","    def queryVector(self, query_vectors, number= 10):\n","        query_vectors = np.array(query_vectors)\n","        query_vectors.reshape(query_vectors.shape[0],1,-1)\n","        #print(self.max_idxdate+1)\n","\n","        date_vectors = self.W[list(range(0,self.max_idxdate+1))]\n","        #print(date_vectors)\n","\n","        date_vectors.reshape(date_vectors.shape[0], 1, -1)\n","\n","        cosines_sim_date = cosine_similarity(query_vectors, date_vectors)\n","\n","\n","\n","        #coor_vectors = self.W[list(range(self.max_idxdate+1,self.min_idxword))]\n","        coor_vectors = self.W[self.max_idxdate+1:self.min_idxword,:]\n","        #print(coor_vectors)\n","\n","        coor_vectors.reshape(coor_vectors.shape[0], 1, -1)\n","        cosines_sim_coor = cosine_similarity(query_vectors, coor_vectors)\n","\n","        word_vectors = self.W[list(range(self.min_idxword, self.max_idxword + 1))]\n","        word_vectors.reshape(word_vectors.shape[0], 1, -1)\n","        cosines_sim_word = cosine_similarity(query_vectors, word_vectors)\n","\n","\n","        indexes_date = np.argsort(cosines_sim_date, )\n","        indexes_coor = np.argsort(cosines_sim_coor) + self.max_idxdate+1\n","        indexes_word = np.argsort(cosines_sim_word) + self.min_idxword\n","\n","        return (indexes_date[:1,-number:], indexes_coor[:1,-number:], indexes_word[:1,-number:])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"F209VamXR-ov","colab_type":"text"},"cell_type":"markdown","source":["#Eval"]},{"metadata":{"id":"VSZCBPT-rMme","colab_type":"code","outputId":"e691b8eb-7271-40a7-9a8a-336cc530ab8c","colab":{"base_uri":"https://localhost:8080/","height":737}},"cell_type":"code","source":["%%time\n","translate = {'w':'Text','l':'Location','t':'Time'}\n","\n","namesets = ['Santiago','LA']\n","results = {'Model':[],'Dataset':[],  'Text':[], 'Location':[],'Time':[]}\n","\n","\n","\n","for i in range(1):\n","    trainST,word2idxST,testST = chargeData_SplitTrainTest('tweets2016_2half.csv')\n","    trainLA,word2idxLA,testLA = chargeData_SplitTrainTest(\"tweetsLA.csv\")\n","    \n","    trainsets = [trainST,  trainLA]\n","    testsets = [testST,  testLA]\n","    for train,test,name in list(zip(trainsets, testsets, namesets)):\n","        QE = QuantitativeEvaluator()\n","\n","\n","        model = RepreAsDoc()\n","\n","        ldadict={True:'lda', False:''}\n","        tfidfdict={True:'tf_idf', False:''}\n","\n","        for lda in [False, True]:\n","            for tfidf in [False, True]:\n","                print(lda,tfidf)\n","                model.fit(train, lda=lda, tf_idf=tfidf)\n","\n","                print('Done Training')\n","\n","\n","                for predict_type in 'wlt':\n","                    QE.get_ranks(test, model, predict_type = predict_type)\n","                    mrr1 = QE.compute_mrr()[0]\n","                    print(f\"{name} MRR {predict_type} {mrr1}\")\n","                    results[translate[predict_type]].append(mrr1)\n","                results['Dataset'].append(name)\n","                results['Model'].append(str(type(model))+'_'+tfidfdict[tfidf]+'_'+ldadict[lda])\n","                df = pd.DataFrame(results)\n","\n","                df.to_csv('resultsRobos.df')\n","    \n","    \n","    \n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["False False\n","Done Training\n","Santiago MRR w 0.6049\n","Santiago MRR l 0.446\n","Santiago MRR t 0.3959\n","False True\n","Done Training\n","Santiago MRR w 0.449\n","Santiago MRR l 0.4356\n","Santiago MRR t 0.4147\n","True False\n","Done Training\n","Santiago MRR w 0.4261\n","Santiago MRR l 0.4276\n","Santiago MRR t 0.4128\n","True True\n","Done Training\n","Santiago MRR w 0.4042\n","Santiago MRR l 0.3933\n","Santiago MRR t 0.3828\n","False False\n","Done Training\n","LA MRR w 0.4468\n","LA MRR l 0.4316\n","LA MRR t 0.3904\n","False True\n","Done Training\n","LA MRR w 0.4123\n","LA MRR l 0.42\n","LA MRR t 0.4021\n","True False\n","Done Training\n","LA MRR w 0.4076\n","LA MRR l 0.4077\n","LA MRR t 0.3967\n","True True\n","Done Training\n","LA MRR w 0.3847\n","LA MRR l 0.3752\n","LA MRR t 0.3662\n","CPU times: user 5h 42min 53s, sys: 4min 34s, total: 5h 47min 27s\n","Wall time: 5h 41min 57s\n"],"name":"stdout"}]},{"metadata":{"id":"DfAp5C2RIDjl","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"id4qVJLaIHTi","colab_type":"text"},"cell_type":"markdown","source":["#Consulta a los datos de AACH"]},{"metadata":{"id":"KFmKuuoh7PBu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"cac0f700-cd1f-4cde-db76-d983dcc630df","executionInfo":{"status":"ok","timestamp":1540836896272,"user_tz":180,"elapsed":2249,"user":{"displayName":"","photoUrl":"","userId":""}}},"cell_type":"code","source":["%%time\n","indexerRob = Indexer()\n","trainRob = indexerRob.fit_transform(data+'robosclean.p', dates_vocab_mincount=0, words_vocab_mincount=10, places_vocab_mincount=0)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["CPU times: user 1.46 s, sys: 59.8 ms, total: 1.52 s\n","Wall time: 1.54 s\n"],"name":"stdout"}]},{"metadata":{"id":"ApxztG31D0kQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e004adb2-489d-4fed-aa49-ea5721edc257","executionInfo":{"status":"ok","timestamp":1540837332801,"user_tz":180,"elapsed":624,"user":{"displayName":"","photoUrl":"","userId":""}}},"cell_type":"code","source":["print(len(trainRob[1]))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["4006\n"],"name":"stdout"}]},{"metadata":{"id":"5KVBEdZ9rVAF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"5c5ca252-bdc5-46fb-8040-10e14ac52137","executionInfo":{"status":"ok","timestamp":1540837545719,"user_tz":180,"elapsed":7693,"user":{"displayName":"","photoUrl":"","userId":""}}},"cell_type":"code","source":["%%time\n","AD_rob = RepreAsDoc()\n","AD_rob.fit(trainRob[0])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["CPU times: user 6.81 s, sys: 266 ms, total: 7.08 s\n","Wall time: 7.08 s\n"],"name":"stdout"}]},{"metadata":{"id":"S5GHUOZwGdoh","colab_type":"code","colab":{}},"cell_type":"code","source":["index = indexerRob.Item2index('portonazo')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"efCy5Mvt-mZg","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"sSme1S1U913f","colab_type":"code","colab":{}},"cell_type":"code","source":["(hours, timesp, words) = AD_rob.queryItem([index], number=10)\n","\n","hours = list(reversed(hours[0]))\n","timesp = list(reversed(timesp[0]))\n","words = list(reversed(words[0]))\n","\n","timesp = [(indexerRob.idx2item[index][1]/100,indexerRob.idx2item[index][0]/100) for index in timesp]\n","words = [indexerRob.idx2item[index] for index in words]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"whnviWgsGqWK","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"CYoiVhJfHTLo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":223},"outputId":"4b57aada-f7d3-4b2f-8325-98cd526a6e39","executionInfo":{"status":"ok","timestamp":1540838249921,"user_tz":180,"elapsed":772,"user":{"displayName":"","photoUrl":"","userId":""}}},"cell_type":"code","source":["print(list(hours))\n","[print(lat,',',lon) for lat,lon in timesp]\n","print(words)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["[0, 23, 22, 21, 1, 3, 20, 4, 2, 19]\n","-33.56 , -70.56\n","-33.51 , -70.66\n","-33.47 , -70.55\n","-33.53 , -70.65\n","-33.58 , -70.59\n","-33.59 , -70.58\n","-33.58 , -70.56\n","-33.55 , -70.59\n","-33.46 , -70.72\n","-33.53 , -70.66\n","['portonazo', 'entrando', 'victima', 'robo', 'intimidacion', 'llegando', 'ingresar', 'domicilio', 'porton', 'ingresando']\n"],"name":"stdout"}]},{"metadata":{"id":"xyeKGY_SIOW8","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"P1BCY5wOIPEE","colab_type":"text"},"cell_type":"markdown","source":["#Consulta a satos de Twitter usando los datos de AACH como referencia."]},{"metadata":{"id":"bo7Yt0CMIUsL","colab_type":"code","colab":{}},"cell_type":"code","source":["df = pd.read_pickle(data+'robosclean.p')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KPA8scmRIZbR","colab_type":"code","colab":{}},"cell_type":"code","source":["df['coor'] = list(zip(list(df['latitude']),list(df['longitude'])))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gqgJFjSIIZeu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"07d05aff-be42-4499-ae66-7bb46a39bd6f","executionInfo":{"status":"ok","timestamp":1540838629175,"user_tz":180,"elapsed":656,"user":{"displayName":"","photoUrl":"","userId":""}}},"cell_type":"code","source":["counter1 = Counter(df['coor'])\n","pairs1 = counter1.most_common(2)\n","pairs1"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[((-70.8852447, -33.6041295), 168), ((-71.3187696, -31.7613364), 106)]"]},"metadata":{"tags":[]},"execution_count":29}]},{"metadata":{"id":"WB7xcTGSIZh3","colab_type":"code","colab":{}},"cell_type":"code","source":["dftest = df[df['coor']==(-70.8852447, -33.6041295)]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g0cbjz7ZIZlj","colab_type":"code","colab":{}},"cell_type":"code","source":["df = pd.read_csv(data+'tweets2016_2half.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WP2LAAljIiE2","colab_type":"code","colab":{}},"cell_type":"code","source":["df.reset_index(inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yQoWnKFeIpkj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"cfd2031d-7bfa-4d8c-f21b-c5dec600bd37","executionInfo":{"status":"ok","timestamp":1540838680274,"user_tz":180,"elapsed":11299,"user":{"displayName":"","photoUrl":"","userId":""}}},"cell_type":"code","source":["%%time\n","indexerST = Indexer()\n","trainST = indexerST.fit_transform(data+'tweets2016_2half.csv', dates_vocab_mincount=0, words_vocab_mincount=100, places_vocab_mincount=50)\n"],"execution_count":35,"outputs":[{"output_type":"stream","text":["CPU times: user 10.3 s, sys: 346 ms, total: 10.7 s\n","Wall time: 10.7 s\n"],"name":"stdout"}]},{"metadata":{"id":"I_thAgpwItJ7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"952d42ad-b573-423f-9c8f-4cbe16e15a3b","executionInfo":{"status":"ok","timestamp":1540838691764,"user_tz":180,"elapsed":4256,"user":{"displayName":"","photoUrl":"","userId":""}}},"cell_type":"code","source":["%%time\n","AD_ST = RepreAsDoc()\n","AD_ST.fit(trainST[0])"],"execution_count":36,"outputs":[{"output_type":"stream","text":["CPU times: user 3.58 s, sys: 11.2 ms, total: 3.59 s\n","Wall time: 3.59 s\n"],"name":"stdout"}]},{"metadata":{"id":"cfDZRWOxJh-N","colab_type":"code","colab":{}},"cell_type":"code","source":["def QueryItem(item, model, indexer, most_close=10):\n","    index = indexer.Item2index(item)\n","    (hours, timesp, words) = model.queryItem([index], number=most_close)\n","    hours = list(reversed(hours[0]))\n","    timesp = list(reversed(timesp[0]))\n","    words = list(reversed(words[0]))\n","    timesp = [(indexer.idx2item[index][0]/100,indexer.idx2item[index][1]/100) for index in timesp]\n","    words = [indexer.idx2item[index] for index in words]\n","    print(list(hours))\n","    [print(lat,',',lon) for lat,lon in timesp]\n","    print(words)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ox2EQMUOIwN_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":414},"outputId":"2a82c44a-a8c8-47e3-9f2e-477494abec07","executionInfo":{"status":"ok","timestamp":1540838810182,"user_tz":180,"elapsed":646,"user":{"displayName":"","photoUrl":"","userId":""}}},"cell_type":"code","source":["QueryItem((-7088,-3360), AD_ST, indexerST, most_close=20)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["[3, 14, 2, 15, 1, 13, 4, 0, 16, 23, 5, 20, 21, 18, 17, 22, 19, 12, 6, 10]\n","-33.44 , -70.62\n","-31.0 , -71.0\n","-33.42 , -70.59\n","-33.45 , -70.62\n","-33.4 , -70.58\n","-33.43 , -70.63\n","-29.95 , -71.26\n","-29.91 , -71.26\n","-33.49 , -70.75\n","-33.61 , -70.88\n","-38.76 , -72.75\n","-33.4 , -70.59\n","-33.44 , -70.6\n","-37.46 , -73.34\n","-33.43 , -70.57\n","-33.44 , -70.58\n","-29.93 , -71.25\n","-38.42 , -72.37\n","-33.42 , -70.62\n","-33.47 , -70.72\n","['nimo', '_http_', 'entrenasano', 'floramour', 'semana', 'miraxhobbies', 'jugueteria', 'mircoles', 'chile', 'hoy', 'buen', 'partiendo', 'santiago', 'buenosdias', 'mejor', 'energa', 'comenzando', 'comenzamos', 'comenzar', 'snapchat']\n"],"name":"stdout"}]},{"metadata":{"id":"TWnF54jGJJqj","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}